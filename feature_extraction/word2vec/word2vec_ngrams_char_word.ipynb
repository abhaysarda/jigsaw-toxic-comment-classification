{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from time import time\n",
    "import gensim\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import Imputer\n",
    "from sklearn import svm\n",
    "from sklearn.metrics import confusion_matrix, f1_score\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data_path = '../../data/raw_data/train.csv'\n",
    "test_data_path = '../../data/raw_data/test.csv'\n",
    "unlabelled_test_path = '../../data/raw_data/unlabelled_test.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(159571, 2)\n",
      "(63978, 2)\n",
      "(89186, 1)\n"
     ]
    }
   ],
   "source": [
    "train_data = pd.read_csv(train_data_path)\n",
    "test_data = pd.read_csv(test_data_path)\n",
    "unlabelled_test = pd.read_csv(unlabelled_test_path)\n",
    "print(train_data.shape)\n",
    "print(test_data.shape)\n",
    "print(unlabelled_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "pandas.core.frame.DataFrame"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(unlabelled_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "comments = list(train_data['Comment'])\n",
    "comments_test = list(test_data['Comment'])\n",
    "unlabelled_test = list(unlabelled_test['Comment'])\n",
    "# Assemble labels\n",
    "data_label = pd.concat([train_data['Labels'], test_data['Labels']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''Simple preprocess removes common accent marks and converts the text to lowercase. \n",
    "Contrast to more advanced preprocessing techniques in tf-idf.'''\n",
    "preprocessed_comments = []\n",
    "for i, line in enumerate(comments):\n",
    "    preprocessed_comments.append(gensim.utils.simple_preprocess(line))\n",
    "for i, line in enumerate(comments_test):\n",
    "    preprocessed_comments.append(gensim.utils.simple_preprocess(line))\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "312735"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preprocessed_comments_total = preprocessed_comments.copy()\n",
    "for i, line in enumerate(unlabelled_test):\n",
    "    preprocessed_comments_total.append(gensim.utils.simple_preprocess(line))\n",
    "len(preprocessed_comments_total)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data, test_data, train_labels, test_labels = train_test_split(preprocessed_comments, data_label , test_size = 0.15, random_state = 2, stratify=data_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "\n",
    "'''\n",
    "def make_feature_vec(words, model, num_features, word_set):\n",
    "    feature_vec = np.zeros((num_features, ), dtype=\"float32\")\n",
    "    number_of_words_added = 0\n",
    "\n",
    "    #convert the vocabulary of the word2vec model to a set for speed\n",
    "    for word in words:\n",
    "        if word in word_set:\n",
    "            number_of_words_added = number_of_words_added + 1\n",
    "            feature_vec = np.add(feature_vec, model[word])\n",
    "    \n",
    "    #Normalize to 1 by dividing by length\n",
    "    feature_vec = np.divide(feature_vec, number_of_words_added)\n",
    "    return feature_vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "''' \n",
    "Convert a list of sentences (our data) to word2vec embedding\n",
    "'''\n",
    "def get_feature_vec_data(model, num_features, data): \n",
    "    current_count = 0\n",
    "    word_set = set(model.wv.index2word)\n",
    "    feature_vec_data = np.zeros((len(data), num_features), dtype=\"float32\")\n",
    "    for comment in data:         \n",
    "        feature_vec_data[current_count] = make_feature_vec(comment, model, num_features, word_set)\n",
    "        current_count = current_count + 1\n",
    "    return feature_vec_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def eval_model(num_features, min_word_count, context, downsampling, preprocessed_comments, train_label, num_epochs):\n",
    "    \n",
    "    start = time()\n",
    "    X_train, X_test, y_train, y_test = train_test_split(preprocessed_comments, train_label, test_size = 0.176, random_state = 2)\n",
    "    print(\"Starting to train the word2vec model.\")\n",
    "    num_of_workers = 6 # Number of threads to be used in parallel\n",
    "\n",
    "    model = gensim.models.Word2Vec(\n",
    "        X_train,\n",
    "        size = num_features,\n",
    "        window = context,\n",
    "        min_count = min_word_count,\n",
    "        workers = num_of_workers,\n",
    "        sample = downsampling)\n",
    "    \n",
    "    model.train(X_train, total_examples = len(X_train), epochs=num_epochs)\n",
    "    print(\"Training complete!\")\n",
    "    model.init_sims(replace=True)\n",
    "    \n",
    "    print(\"Extracting feature representation from word2vec model.\")\n",
    "    wv_data = get_feature_vec_data(model, num_features, X_train)\n",
    "    wv_data = Imputer().fit_transform(wv_data)\n",
    "    \n",
    "    wv_test = get_feature_vec_data(model, num_features, X_test)\n",
    "    wv_test = Imputer().fit_transform(wv_test)\n",
    "    clf = svm.LinearSVC(dual=False, class_weight=\"balanced\")\n",
    "    print(\"Fitting SVM to data.\")\n",
    "    \n",
    "    clf.fit(wv_data, y_train)\n",
    "\n",
    "    result = clf.predict(wv_test)\n",
    "    #conf_mat = confusion_matrix(test_data['Labels'], result)\n",
    "    fscore = f1_score(y_test, result, 'macro')\n",
    "    end = time()\n",
    "    print(\"The total time taken for this iteration is :\", end-start)\n",
    "    print(\"F Score is: \", fscore)\n",
    "    return fscore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
