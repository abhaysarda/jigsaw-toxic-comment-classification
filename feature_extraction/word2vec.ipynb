{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Verify later\n",
    "Since word2vec relies on predicting words by context, we do not need to eliminate stop words, since they eliminate valuable contextual information.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gensim\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data_path = '../data/raw_data/train.csv'\n",
    "test_data_path = '../data/raw_data/test.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(159571, 2)\n",
      "(63978, 2)\n"
     ]
    }
   ],
   "source": [
    "train_data = pd.read_csv(train_data_path)\n",
    "test_data = pd.read_csv(test_data_path)\n",
    "print(train_data.shape)\n",
    "print(test_data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Explanation\\r\\r\\nWhy the edits made under my username Hardcore Metallica Fan were reverted? They weren't vandalisms, just closure on some GAs after I voted at New York Dolls FAC. And please don't remove the template from the talk page since I'm retired now.89.205.38.27\""
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "comments = list(train_data['Comment'])\n",
    "comments[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''Simple preprocess removes common accent marks and converts the text to lowercase. \n",
    "Contrast to more advanced preprocessing techniques in tf-idf.'''\n",
    "preprocessed_comments = []\n",
    "for i, line in enumerate(comments):\n",
    "    preprocessed_comments.append(gensim.utils.simple_preprocess(line))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "comments_test = list(test_data['Comment'])\n",
    "preprocessed_test = []\n",
    "for i, line in enumerate(comments_test):\n",
    "    preprocessed_test.append(gensim.utils.simple_preprocess(line))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['explanation',\n",
       " 'why',\n",
       " 'the',\n",
       " 'edits',\n",
       " 'made',\n",
       " 'under',\n",
       " 'my',\n",
       " 'username',\n",
       " 'hardcore',\n",
       " 'metallica',\n",
       " 'fan',\n",
       " 'were',\n",
       " 'reverted',\n",
       " 'they',\n",
       " 'weren',\n",
       " 'vandalisms',\n",
       " 'just',\n",
       " 'closure',\n",
       " 'on',\n",
       " 'some',\n",
       " 'gas',\n",
       " 'after',\n",
       " 'voted',\n",
       " 'at',\n",
       " 'new',\n",
       " 'york',\n",
       " 'dolls',\n",
       " 'fac',\n",
       " 'and',\n",
       " 'please',\n",
       " 'don',\n",
       " 'remove',\n",
       " 'the',\n",
       " 'template',\n",
       " 'from',\n",
       " 'the',\n",
       " 'talk',\n",
       " 'page',\n",
       " 'since',\n",
       " 'retired',\n",
       " 'now']"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preprocessed_comments[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''The number of features indicate what dimension of a word vector we shall be using'''\n",
    "num_features = 300 # The dimension of the word vector(HyperParameter)\n",
    "min_word_count = 3# The minimum word count(HyperParameter)\n",
    "num_of_workers = 4 # Number of threads to be used in parallel\n",
    "context = 10 # The context window size (HyperParameter)\n",
    "downsampling = 1e-3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = gensim.models.Word2Vec(\n",
    "        preprocessed_comments,\n",
    "        size = num_features,\n",
    "        window = context,\n",
    "        min_count = min_word_count,\n",
    "        workers = num_of_workers,\n",
    "        sample = downsampling)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(77612069, 101876800)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.train(preprocessed_comments, total_examples = len(comments), epochs=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<bound method BaseWordEmbeddingsModel.estimate_memory of <gensim.models.word2vec.Word2Vec object at 0x00000235C9A71C88>>"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.init_sims(replace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "59701"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Vocabulary size\n",
    "len(model.wv.vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('hi', 0.6357199549674988),\n",
       " ('hello', 0.5268846750259399),\n",
       " ('yo', 0.472095251083374),\n",
       " ('howdy', 0.4563082456588745),\n",
       " ('dude', 0.45139196515083313),\n",
       " ('sup', 0.4460800886154175),\n",
       " ('haha', 0.4426163136959076),\n",
       " ('mate', 0.4378395080566406),\n",
       " ('btw', 0.4340026080608368),\n",
       " ('hahahaha', 0.42958885431289673)]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w1 = \"hey\"\n",
    "model.wv.most_similar(positive=w1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Abhay\\Anaconda3\\envs\\toxic-comments\\lib\\site-packages\\ipykernel_launcher.py:1: DeprecationWarning: Call to deprecated `doesnt_match` (Method will be removed in 4.0.0, use self.wv.doesnt_match() instead).\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'kitchen'"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.doesnt_match(\"man woman child kitchen\".split())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once we have a word2vec embedding trained, we still need to take into account multiple length comments. Because of which we cannot simply convert a paragraph to a vector embedding. However, we can take many different approaches, one of which is averaging the word vectors. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_feature_vec(words, model, num_features):\n",
    "    feature_vec = np.zeros((num_features, ), dtype=\"float32\")\n",
    "    number_of_words_added = 0\n",
    "    \n",
    "    #convert the vocabulary of the word2vec model to a set for speed\n",
    "    word_set = set(model.wv.index2word)\n",
    "    for word in words:\n",
    "        if word in word_set:\n",
    "            number_of_words_added = number_of_words_added + 1\n",
    "            feature_vec = np.add(feature_vec, model[word])\n",
    "    \n",
    "    #Normalize to 1 by dividing by length\n",
    "    feature_vec = np.divide(feature_vec, number_of_words_added)\n",
    "    return feature_vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-5.36105130e-03 -4.12288075e-03 -8.66610650e-03  1.52602168e-02\n",
      " -1.12523902e-02 -3.89550882e-03 -1.98000297e-02  1.18375907e-03\n",
      "  1.22291446e-02  2.22750939e-02  2.80690915e-03 -1.56473219e-02\n",
      " -6.44711405e-03 -2.02375408e-02 -3.34329624e-03 -1.69196120e-03\n",
      "  6.34606229e-03 -1.97174447e-03  4.01650369e-03 -1.29603120e-02\n",
      " -2.20447686e-02  1.83563767e-04  1.12800812e-02  5.34207327e-04\n",
      " -1.01370402e-02 -6.78514922e-03  1.98464096e-02 -1.72577868e-03\n",
      " -5.87076973e-03 -1.84394326e-02  1.30102551e-02  1.19437659e-02\n",
      "  2.21704021e-02  6.86688232e-04  1.44102843e-03 -2.87136771e-02\n",
      "  9.92098916e-03 -9.96799674e-03 -3.16679813e-02 -3.66068911e-03\n",
      " -1.28029482e-02 -1.64133925e-02  2.12430907e-03  1.77914314e-02\n",
      " -8.32850300e-03 -1.39359117e-03  2.28292346e-02 -1.07039353e-02\n",
      "  1.70682240e-02 -7.75591098e-03  1.08979968e-02 -2.04704311e-02\n",
      " -1.08303018e-02 -9.26215388e-03 -1.66471247e-02 -7.32635520e-03\n",
      "  1.04776770e-02  5.96658420e-03  2.99230567e-03  6.95470115e-03\n",
      "  3.58129083e-03 -8.13404284e-03 -1.97413079e-02  1.45237576e-02\n",
      " -1.32961068e-02 -1.17478892e-02 -1.03354473e-02 -9.48274916e-04\n",
      " -1.50152417e-02 -4.62635839e-03  7.35323876e-03  1.88025404e-02\n",
      " -1.26852700e-02  1.47403218e-02  8.22899770e-03  5.01477392e-03\n",
      " -1.74903050e-02  1.90623850e-02 -1.82810929e-02  8.47247662e-04\n",
      " -4.14835615e-03  1.13218678e-02  2.88242735e-02  2.31543109e-02\n",
      " -9.65051877e-04  2.83663329e-02 -6.64494745e-03 -1.21395948e-04\n",
      " -1.43351769e-02 -8.38479213e-03 -9.52267612e-04  9.50414571e-04\n",
      " -1.63003821e-02 -4.00834624e-03 -2.93823052e-03  7.53068412e-03\n",
      "  1.08502442e-02  6.64287712e-03  9.54433158e-03  1.75409124e-03\n",
      " -2.58987816e-03  1.50408177e-02 -2.14485526e-02  9.24030133e-03\n",
      "  1.12305535e-02 -1.79755390e-02  4.39956877e-03 -1.14492439e-04\n",
      "  2.35173805e-03 -3.87807237e-03  2.23250091e-02  6.35083718e-03\n",
      " -9.48482833e-04 -1.12357978e-02 -2.83580646e-03  8.55150633e-03\n",
      " -3.16280462e-02 -2.58830516e-03  1.40585219e-02 -1.67565402e-02\n",
      " -9.40517895e-03 -6.98480383e-03 -5.42481337e-03  5.82046388e-03\n",
      " -3.38817656e-04 -2.37864293e-02  4.31546336e-03  1.31211486e-02\n",
      " -1.68757036e-03  4.11034189e-03 -1.02841975e-02  1.01510715e-02\n",
      "  1.13588311e-02  5.22555970e-03 -1.31436472e-03 -2.05225907e-02\n",
      " -9.83275101e-03  6.62020734e-03 -2.47043669e-02 -2.28637201e-03\n",
      "  7.15757580e-03  2.11492311e-02  2.17413474e-02 -1.95400175e-02\n",
      " -1.20128726e-03 -4.77970811e-03 -1.11948820e-02  2.88700918e-03\n",
      " -1.18052959e-02  3.66898719e-03 -2.56105103e-02  1.35560334e-03\n",
      "  5.07984124e-03  4.63850774e-05  4.93540661e-03  9.33283381e-03\n",
      " -1.12966448e-02  6.95838500e-03 -2.25707167e-03  6.27624849e-03\n",
      " -1.03761591e-02 -1.63969360e-02 -9.26346704e-03  9.40372609e-03\n",
      " -1.11342780e-02 -7.50814984e-03 -7.46621285e-03  1.18387835e-02\n",
      "  7.73117505e-03  1.37366783e-02 -3.51685286e-03 -9.07194987e-03\n",
      " -1.55051250e-03  1.70955304e-02 -1.18004088e-03  5.05976193e-03\n",
      "  7.54024321e-03 -1.67424437e-02  1.65184103e-02 -2.35592555e-02\n",
      "  4.24148561e-03 -6.38453336e-03 -1.85772590e-03  3.25736403e-03\n",
      "  1.12774037e-03  3.00266966e-03 -2.46242285e-02 -6.42754184e-03\n",
      "  1.45031288e-02  1.22804362e-02 -1.83197632e-02  4.71321540e-03\n",
      "  5.43039804e-03 -9.22039058e-03 -1.82831176e-02  5.46269538e-03\n",
      " -5.99877350e-03 -2.15008296e-03 -1.30709521e-02  8.57519917e-03\n",
      " -1.65043697e-02  1.24931359e-03  1.07496595e-02 -1.65883135e-02\n",
      " -6.50244532e-03  1.82928622e-03 -6.05424354e-03  2.09540892e-02\n",
      " -1.04156164e-02  1.81225445e-02  8.60370882e-03  2.32785428e-03\n",
      " -2.10891222e-03 -1.74421165e-02 -5.12017775e-03  5.68209682e-03\n",
      "  4.62501263e-03 -5.28562814e-03 -8.35322868e-03 -1.09238233e-02\n",
      " -1.12931291e-03 -6.40432723e-03  7.77781289e-03  4.03755344e-03\n",
      " -1.98025675e-03  4.66956897e-03  4.03788313e-03  5.90555603e-03\n",
      "  1.88937876e-02  9.20946186e-04  1.99293694e-03  1.50260404e-02\n",
      " -7.73955323e-03 -8.83388333e-03  1.50699560e-02  5.23694744e-03\n",
      "  1.81493126e-02  4.80996957e-03 -1.19637931e-02  1.11192488e-03\n",
      "  1.75604597e-02  1.68782603e-02 -7.09929643e-03  2.99111661e-02\n",
      "  5.31640602e-04  7.70308427e-04 -1.67091191e-02 -2.58537708e-03\n",
      " -2.07947008e-02  3.97232082e-03  1.44891941e-03  1.21118203e-02\n",
      " -1.08726649e-02 -1.30626075e-02 -1.01346737e-02  3.74468439e-03\n",
      "  6.72822539e-03 -7.79648824e-03 -2.00499389e-02 -1.87306106e-02\n",
      "  5.51887974e-03  1.25689013e-02 -4.60153166e-03 -8.29156372e-04\n",
      "  1.39643243e-02  1.81954429e-02  1.95115153e-02  1.68622867e-03\n",
      "  1.58941746e-03 -1.52823201e-03 -1.74103363e-03 -1.33628715e-02\n",
      "  1.01788063e-02 -2.47919024e-03 -1.41337542e-02 -3.74312163e-03\n",
      "  2.80335895e-03 -5.61826816e-03 -8.47746246e-03 -1.03977742e-02\n",
      " -5.86910499e-03  1.29181035e-02  1.32588297e-02 -8.28950573e-03\n",
      " -1.87264278e-03  9.51148383e-03 -1.00798076e-02 -1.35264487e-03\n",
      " -3.35684791e-02  1.41471243e-02  4.93884645e-03 -3.03482916e-02\n",
      " -1.57211870e-02  3.01952334e-03 -6.06902223e-03 -1.95737835e-02\n",
      " -5.07935230e-03 -2.94705067e-04  4.52493038e-03  9.44570056e-04]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Abhay\\Anaconda3\\envs\\toxic-comments\\lib\\site-packages\\ipykernel_launcher.py:10: DeprecationWarning: Call to deprecated `__getitem__` (Method will be removed in 4.0.0, use self.wv.__getitem__() instead).\n",
      "  # Remove the CWD from sys.path while we load stuff.\n"
     ]
    }
   ],
   "source": [
    "print(make_feature_vec(preprocessed_comments[0], model, 300))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "''' \n",
    "Convert a list of sentences (our data) to word2vec embedding\n",
    "'''\n",
    "def get_feature_vec_data(model, num_features, data):\n",
    "    current_count = 0\n",
    "    \n",
    "    feature_vec_data = np.zeros((len(data), num_features), dtype=\"float32\")\n",
    "    \n",
    "    for comment in data:\n",
    "        if current_count % 1000 == 0:\n",
    "            print(\"Current processing comment %d of %d\" % (current_count, len(data)))\n",
    "            \n",
    "        feature_vec_data[current_count] = make_feature_vec(comment, model, num_features)\n",
    "        current_count = current_count + 1\n",
    "    return feature_vec_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current processing comment 0 of 159571\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Abhay\\Anaconda3\\envs\\toxic-comments\\lib\\site-packages\\ipykernel_launcher.py:10: DeprecationWarning: Call to deprecated `__getitem__` (Method will be removed in 4.0.0, use self.wv.__getitem__() instead).\n",
      "  # Remove the CWD from sys.path while we load stuff.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current processing comment 1000 of 159571\n",
      "Current processing comment 2000 of 159571\n",
      "Current processing comment 3000 of 159571\n",
      "Current processing comment 4000 of 159571\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Abhay\\Anaconda3\\envs\\toxic-comments\\lib\\site-packages\\ipykernel_launcher.py:13: RuntimeWarning: invalid value encountered in true_divide\n",
      "  del sys.path[0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current processing comment 5000 of 159571\n",
      "Current processing comment 6000 of 159571\n",
      "Current processing comment 7000 of 159571\n",
      "Current processing comment 8000 of 159571\n",
      "Current processing comment 9000 of 159571\n",
      "Current processing comment 10000 of 159571\n",
      "Current processing comment 11000 of 159571\n",
      "Current processing comment 12000 of 159571\n",
      "Current processing comment 13000 of 159571\n",
      "Current processing comment 14000 of 159571\n",
      "Current processing comment 15000 of 159571\n",
      "Current processing comment 16000 of 159571\n",
      "Current processing comment 17000 of 159571\n",
      "Current processing comment 18000 of 159571\n",
      "Current processing comment 19000 of 159571\n",
      "Current processing comment 20000 of 159571\n",
      "Current processing comment 21000 of 159571\n",
      "Current processing comment 22000 of 159571\n",
      "Current processing comment 23000 of 159571\n",
      "Current processing comment 24000 of 159571\n",
      "Current processing comment 25000 of 159571\n",
      "Current processing comment 26000 of 159571\n",
      "Current processing comment 27000 of 159571\n",
      "Current processing comment 28000 of 159571\n",
      "Current processing comment 29000 of 159571\n",
      "Current processing comment 30000 of 159571\n",
      "Current processing comment 31000 of 159571\n",
      "Current processing comment 32000 of 159571\n",
      "Current processing comment 33000 of 159571\n",
      "Current processing comment 34000 of 159571\n",
      "Current processing comment 35000 of 159571\n",
      "Current processing comment 36000 of 159571\n",
      "Current processing comment 37000 of 159571\n",
      "Current processing comment 38000 of 159571\n",
      "Current processing comment 39000 of 159571\n",
      "Current processing comment 40000 of 159571\n",
      "Current processing comment 41000 of 159571\n",
      "Current processing comment 42000 of 159571\n",
      "Current processing comment 43000 of 159571\n",
      "Current processing comment 44000 of 159571\n",
      "Current processing comment 45000 of 159571\n",
      "Current processing comment 46000 of 159571\n",
      "Current processing comment 47000 of 159571\n",
      "Current processing comment 48000 of 159571\n",
      "Current processing comment 49000 of 159571\n",
      "Current processing comment 50000 of 159571\n",
      "Current processing comment 51000 of 159571\n",
      "Current processing comment 52000 of 159571\n",
      "Current processing comment 53000 of 159571\n",
      "Current processing comment 54000 of 159571\n",
      "Current processing comment 55000 of 159571\n",
      "Current processing comment 56000 of 159571\n",
      "Current processing comment 57000 of 159571\n",
      "Current processing comment 58000 of 159571\n",
      "Current processing comment 59000 of 159571\n",
      "Current processing comment 60000 of 159571\n",
      "Current processing comment 61000 of 159571\n",
      "Current processing comment 62000 of 159571\n",
      "Current processing comment 63000 of 159571\n",
      "Current processing comment 64000 of 159571\n",
      "Current processing comment 65000 of 159571\n",
      "Current processing comment 66000 of 159571\n",
      "Current processing comment 67000 of 159571\n",
      "Current processing comment 68000 of 159571\n",
      "Current processing comment 69000 of 159571\n",
      "Current processing comment 70000 of 159571\n",
      "Current processing comment 71000 of 159571\n",
      "Current processing comment 72000 of 159571\n",
      "Current processing comment 73000 of 159571\n",
      "Current processing comment 74000 of 159571\n",
      "Current processing comment 75000 of 159571\n",
      "Current processing comment 76000 of 159571\n",
      "Current processing comment 77000 of 159571\n",
      "Current processing comment 78000 of 159571\n",
      "Current processing comment 79000 of 159571\n",
      "Current processing comment 80000 of 159571\n",
      "Current processing comment 81000 of 159571\n",
      "Current processing comment 82000 of 159571\n",
      "Current processing comment 83000 of 159571\n",
      "Current processing comment 84000 of 159571\n",
      "Current processing comment 85000 of 159571\n",
      "Current processing comment 86000 of 159571\n",
      "Current processing comment 87000 of 159571\n",
      "Current processing comment 88000 of 159571\n",
      "Current processing comment 89000 of 159571\n",
      "Current processing comment 90000 of 159571\n",
      "Current processing comment 91000 of 159571\n",
      "Current processing comment 92000 of 159571\n",
      "Current processing comment 93000 of 159571\n",
      "Current processing comment 94000 of 159571\n",
      "Current processing comment 95000 of 159571\n",
      "Current processing comment 96000 of 159571\n",
      "Current processing comment 97000 of 159571\n",
      "Current processing comment 98000 of 159571\n",
      "Current processing comment 99000 of 159571\n",
      "Current processing comment 100000 of 159571\n",
      "Current processing comment 101000 of 159571\n",
      "Current processing comment 102000 of 159571\n",
      "Current processing comment 103000 of 159571\n",
      "Current processing comment 104000 of 159571\n",
      "Current processing comment 105000 of 159571\n",
      "Current processing comment 106000 of 159571\n",
      "Current processing comment 107000 of 159571\n",
      "Current processing comment 108000 of 159571\n",
      "Current processing comment 109000 of 159571\n",
      "Current processing comment 110000 of 159571\n",
      "Current processing comment 111000 of 159571\n",
      "Current processing comment 112000 of 159571\n",
      "Current processing comment 113000 of 159571\n",
      "Current processing comment 114000 of 159571\n",
      "Current processing comment 115000 of 159571\n",
      "Current processing comment 116000 of 159571\n",
      "Current processing comment 117000 of 159571\n",
      "Current processing comment 118000 of 159571\n",
      "Current processing comment 119000 of 159571\n",
      "Current processing comment 120000 of 159571\n",
      "Current processing comment 121000 of 159571\n",
      "Current processing comment 122000 of 159571\n",
      "Current processing comment 123000 of 159571\n",
      "Current processing comment 124000 of 159571\n",
      "Current processing comment 125000 of 159571\n",
      "Current processing comment 126000 of 159571\n",
      "Current processing comment 127000 of 159571\n",
      "Current processing comment 128000 of 159571\n",
      "Current processing comment 129000 of 159571\n",
      "Current processing comment 130000 of 159571\n",
      "Current processing comment 131000 of 159571\n",
      "Current processing comment 132000 of 159571\n",
      "Current processing comment 133000 of 159571\n",
      "Current processing comment 134000 of 159571\n",
      "Current processing comment 135000 of 159571\n",
      "Current processing comment 136000 of 159571\n",
      "Current processing comment 137000 of 159571\n",
      "Current processing comment 138000 of 159571\n",
      "Current processing comment 139000 of 159571\n",
      "Current processing comment 140000 of 159571\n",
      "Current processing comment 141000 of 159571\n",
      "Current processing comment 142000 of 159571\n",
      "Current processing comment 143000 of 159571\n",
      "Current processing comment 144000 of 159571\n",
      "Current processing comment 145000 of 159571\n",
      "Current processing comment 146000 of 159571\n",
      "Current processing comment 147000 of 159571\n",
      "Current processing comment 148000 of 159571\n",
      "Current processing comment 149000 of 159571\n",
      "Current processing comment 150000 of 159571\n",
      "Current processing comment 151000 of 159571\n",
      "Current processing comment 152000 of 159571\n",
      "Current processing comment 153000 of 159571\n",
      "Current processing comment 154000 of 159571\n",
      "Current processing comment 155000 of 159571\n",
      "Current processing comment 156000 of 159571\n",
      "Current processing comment 157000 of 159571\n",
      "Current processing comment 158000 of 159571\n",
      "Current processing comment 159000 of 159571\n"
     ]
    }
   ],
   "source": [
    "wv_data = get_feature_vec_data(model, num_features, preprocessed_comments)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(159571, 300)"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wv_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current processing comment 0 of 63978\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Abhay\\Anaconda3\\envs\\toxic-comments\\lib\\site-packages\\ipykernel_launcher.py:10: DeprecationWarning: Call to deprecated `__getitem__` (Method will be removed in 4.0.0, use self.wv.__getitem__() instead).\n",
      "  # Remove the CWD from sys.path while we load stuff.\n",
      "C:\\Users\\Abhay\\Anaconda3\\envs\\toxic-comments\\lib\\site-packages\\ipykernel_launcher.py:13: RuntimeWarning: invalid value encountered in true_divide\n",
      "  del sys.path[0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current processing comment 1000 of 63978\n",
      "Current processing comment 2000 of 63978\n",
      "Current processing comment 3000 of 63978\n",
      "Current processing comment 4000 of 63978\n",
      "Current processing comment 5000 of 63978\n",
      "Current processing comment 6000 of 63978\n",
      "Current processing comment 7000 of 63978\n",
      "Current processing comment 8000 of 63978\n",
      "Current processing comment 9000 of 63978\n",
      "Current processing comment 10000 of 63978\n",
      "Current processing comment 11000 of 63978\n",
      "Current processing comment 12000 of 63978\n",
      "Current processing comment 13000 of 63978\n",
      "Current processing comment 14000 of 63978\n",
      "Current processing comment 15000 of 63978\n",
      "Current processing comment 16000 of 63978\n",
      "Current processing comment 17000 of 63978\n",
      "Current processing comment 18000 of 63978\n",
      "Current processing comment 19000 of 63978\n",
      "Current processing comment 20000 of 63978\n",
      "Current processing comment 21000 of 63978\n",
      "Current processing comment 22000 of 63978\n",
      "Current processing comment 23000 of 63978\n",
      "Current processing comment 24000 of 63978\n",
      "Current processing comment 25000 of 63978\n",
      "Current processing comment 26000 of 63978\n",
      "Current processing comment 27000 of 63978\n",
      "Current processing comment 28000 of 63978\n",
      "Current processing comment 29000 of 63978\n",
      "Current processing comment 30000 of 63978\n",
      "Current processing comment 31000 of 63978\n",
      "Current processing comment 32000 of 63978\n",
      "Current processing comment 33000 of 63978\n",
      "Current processing comment 34000 of 63978\n",
      "Current processing comment 35000 of 63978\n",
      "Current processing comment 36000 of 63978\n",
      "Current processing comment 37000 of 63978\n",
      "Current processing comment 38000 of 63978\n",
      "Current processing comment 39000 of 63978\n",
      "Current processing comment 40000 of 63978\n",
      "Current processing comment 41000 of 63978\n",
      "Current processing comment 42000 of 63978\n",
      "Current processing comment 43000 of 63978\n",
      "Current processing comment 44000 of 63978\n",
      "Current processing comment 45000 of 63978\n",
      "Current processing comment 46000 of 63978\n",
      "Current processing comment 47000 of 63978\n",
      "Current processing comment 48000 of 63978\n",
      "Current processing comment 49000 of 63978\n",
      "Current processing comment 50000 of 63978\n",
      "Current processing comment 51000 of 63978\n",
      "Current processing comment 52000 of 63978\n",
      "Current processing comment 53000 of 63978\n",
      "Current processing comment 54000 of 63978\n",
      "Current processing comment 55000 of 63978\n",
      "Current processing comment 56000 of 63978\n",
      "Current processing comment 57000 of 63978\n",
      "Current processing comment 58000 of 63978\n",
      "Current processing comment 59000 of 63978\n",
      "Current processing comment 60000 of 63978\n",
      "Current processing comment 61000 of 63978\n",
      "Current processing comment 62000 of 63978\n",
      "Current processing comment 63000 of 63978\n"
     ]
    }
   ],
   "source": [
    "# Do the same for test data\n",
    "wv_test = get_feature_vec_data(model, num_features, preprocessed_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import Imputer\n",
    "wv_test = Imputer().fit_transform(wv_test)\n",
    "wv_data = Imputer().fit_transform(wv_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting random forest to data.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[56735,  1000],\n",
       "       [ 3633,  2610]], dtype=int64)"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "forest = RandomForestClassifier(n_estimators=100)\n",
    "\n",
    "print(\"Fitting random forest to data.\")\n",
    "forest = forest.fit(wv_data, train_data['Labels'])\n",
    "\n",
    "result = forest.predict(wv_test)\n",
    "confusion_matrix(test_data['Labels'], result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
