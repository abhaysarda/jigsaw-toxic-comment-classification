{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# IMPORTS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd, numpy as np\n",
    "import sklearn\n",
    "import scipy.sparse\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "from ipynb.fs.full.Data_Preprocessing import remove_stop_words, make_feature_vec"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## UNCOMMENT TO PROCESS DATA FROM SCRATCH"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# data = pd.read_csv('../data/train.csv')\n",
    "# labels=(data[\"toxic\"] | data[\"severe_toxic\"] | data[\"obscene\"] | data[\"threat\"] | data[\"insult\"] | data[\"identity_hate\"])\n",
    "# train_data = data[0:100000]\n",
    "# test_data = data[100001:]\n",
    "# train_labels = labels[0:100000]\n",
    "# test_labels = labels[100001:]\n",
    "\n",
    "### CLEANING DATA \n",
    "# clean_comments = remove_stop_words(data)\n",
    "# ret = make_feature_vec(clean_comments)\n",
    "\n",
    "# vocab = ret['vocab']\n",
    "# train_feature_vectors_sparse = ret['train_feature_vectors_sparse'][0:100000]\n",
    "# test_feature_vectors_sparse = ret['train_feature_vectors_sparse'][100001:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# USE ALREADY PROCESSED DATA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "labels = pd.read_csv('../data/Processed/labels.csv')[\"labels\"]\n",
    "train_labels = labels[0:100000]\n",
    "test_labels = labels[100001:]\n",
    "\n",
    "train_feature_vectors_sparse_load = scipy.sparse.load_npz('../data/Processed/sparse_train_matrix.npz')\n",
    "\n",
    "train_feature_vectors_sparse = train_feature_vectors_sparse_load[0:100000]\n",
    "test_feature_vectors_sparse = train_feature_vectors_sparse_load[100001:]\n",
    "vocab = pd.read_csv('../data/Processed/vocab.csv')[\"vocab\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of train vec: (100000, 168595)\n",
      "Shape of test vec: (59570, 168595)\n"
     ]
    }
   ],
   "source": [
    "print(\"Shape of train vec:\", train_feature_vectors_sparse.shape)\n",
    "print(\"Shape of test vec:\", test_feature_vectors_sparse.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TRAINING COMPLEMENT-NB CLASSIFIER"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "% of 1s in taining data 0.101292596945\n",
      "% if 1s in test data 0.10191\n",
      "\n",
      "Precision =  0.712462711303\n",
      "Recall =  0.588904109589\n",
      "F_score =  0.644817759112\n",
      "CCR =  0.92049689441\n",
      "\n",
      "Confusion Matrix: \n",
      " [[50535  3001]\n",
      " [ 1735  4299]]\n"
     ]
    }
   ],
   "source": [
    "#TRAINING\n",
    "from sklearn.naive_bayes import ComplementNB\n",
    "clf = ComplementNB()\n",
    "clf.fit(train_feature_vectors_sparse, train_labels)\n",
    "\n",
    "# PREDICTION\n",
    "predictions = clf.predict(test_feature_vectors_sparse)\n",
    "\n",
    "print(\"% of 1s in taining data\",sum(test_labels)/len(test_labels))\n",
    "print(\"% if 1s in test data\", sum(train_labels)/len(train_labels))\n",
    "print()\n",
    "\n",
    "# PERFORMANCE METRICS\n",
    "\n",
    "confmat = sklearn.metrics.confusion_matrix(test_labels, predictions)\n",
    "\n",
    "precision = confmat[1,1]/(confmat[1,1] + confmat[1,0])\n",
    "recall = confmat[1,1]/(confmat[1,1] + confmat[0,1])\n",
    "fScore = (2*precision*recall)/(recall+precision)\n",
    "ccr = (confmat[0,0] + confmat[1,1])/(sum(sum(confmat)))\n",
    "\n",
    "print(\"Precision = \",precision)\n",
    "print(\"Recall = \",recall)\n",
    "print(\"F_score = \",fScore)\n",
    "print(\"CCR = \",ccr)\n",
    "print()\n",
    "print(\"Confusion Matrix: \\n\", confmat)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### TEST DATA PROCESSING - STRAY BLOCK FOR LATER USAGE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "##### STRAY BLOCK FOR LATER USAGE #####\n",
    "\n",
    "# # creating sparse representation of test feature vectors\n",
    "# vocab_mapping=set(zip([i for i in range (0,len(vocab))],vocab))\n",
    "# print(\"Starting to create bag of words...\")\n",
    "# vectorizer_test = CountVectorizer(analyzer=\"word\", tokenizer=None, preprocessor=None, vocabulary=vocab_mapping)\n",
    "# test_feature_vectors_sparse = vectorizer_test.fit_transform(clean_test_comments)\n",
    "test_feature_vectors_full = test_feature_vectors_sparse.toarray()\n",
    "train_feature_vectors_full = train_feature_vectors_sparse.toarray()\n",
    "# print(\"Bag of words created.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# USING NORMAL MULTINOMIAL-NB, THE F-SCORE DECREASES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision =  0.619489559165\n",
      "Recall =  0.762079510703\n",
      "F_score =  0.683426272968\n",
      "CCR =  0.941866711432\n",
      "\n",
      "Confusion Matrix: \n",
      " [[52369  1167]\n",
      " [ 2296  3738]]\n"
     ]
    }
   ],
   "source": [
    "# TRAINING\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "clf = MultinomialNB()\n",
    "clf.fit(train_feature_vectors_sparse, train_labels)\n",
    "\n",
    "# PREDICTION\n",
    "predictions = clf.predict(test_feature_vectors_sparse)\n",
    "\n",
    "\n",
    "# PERFORMANCE METRICS\n",
    "\n",
    "confmat = sklearn.metrics.confusion_matrix(test_labels, predictions)\n",
    "\n",
    "precision = confmat[1,1]/(confmat[1,1] + confmat[1,0])\n",
    "recall = confmat[1,1]/(confmat[1,1] + confmat[0,1])\n",
    "fScore = (2*precision*recall)/(recall+precision)\n",
    "ccr = (confmat[0,0] + confmat[1,1])/(sum(sum(confmat)))\n",
    "\n",
    "print(\"Precision = \",precision)\n",
    "print(\"Recall = \",recall)\n",
    "print(\"F_score = \",fScore)\n",
    "print(\"CCR = \",ccr)\n",
    "print()\n",
    "print(\"Confusion Matrix: \\n\", confmat)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# TF-IDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TfidfTransformer(norm=None, smooth_idf=True, sublinear_tf=False, use_idf=True)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "tfidf_transformer = TfidfTransformer(norm=None, use_idf=True, smooth_idf=True, sublinear_tf=False)\n",
    "X_train_tfidf = tfidf_transformer.fit_transform(train_feature_vectors_sparse)\n",
    "X_test_tfidf = tfidf_transformer.transform(test_feature_vectors_sparse)\n",
    "tfidf_transformer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Multinomial NB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision =  0.799635399403\n",
      "Recall =  0.456610201571\n",
      "F_score =  0.581290283718\n",
      "CCR =  0.883313748531\n",
      "\n",
      "Confusion Matrix: \n",
      " [[47794  5742]\n",
      " [ 1209  4825]]\n"
     ]
    }
   ],
   "source": [
    "# TRAINING\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "clf = MultinomialNB()\n",
    "clf.fit(X_train_tfidf, train_labels)\n",
    "\n",
    "# PREDICTION\n",
    "predictions = clf.predict(X_test_tfidf)\n",
    "\n",
    "\n",
    "# PERFORMANCE METRICS\n",
    "\n",
    "confmat = sklearn.metrics.confusion_matrix(test_labels, predictions)\n",
    "\n",
    "precision = confmat[1,1]/(confmat[1,1] + confmat[1,0])\n",
    "recall = confmat[1,1]/(confmat[1,1] + confmat[0,1])\n",
    "fScore = (2*precision*recall)/(recall+precision)\n",
    "ccr = (confmat[0,0] + confmat[1,1])/(sum(sum(confmat)))\n",
    "\n",
    "print(\"Precision = \",precision)\n",
    "print(\"Recall = \",recall)\n",
    "print(\"F_score = \",fScore)\n",
    "print(\"CCR = \",ccr)\n",
    "print()\n",
    "print(\"Confusion Matrix: \\n\", confmat)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Complement NB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision =  0.809744779582\n",
      "Recall =  0.439428006116\n",
      "F_score =  0.569696263044\n",
      "CCR =  0.876095350008\n",
      "\n",
      "Confusion Matrix: \n",
      " [[47303  6233]\n",
      " [ 1148  4886]]\n"
     ]
    }
   ],
   "source": [
    "# TRAINING\n",
    "from sklearn.naive_bayes import ComplementNB\n",
    "clf = ComplementNB()\n",
    "clf.fit(X_train_tfidf, train_labels)\n",
    "\n",
    "# PREDICTION\n",
    "predictions = clf.predict(X_test_tfidf)\n",
    "\n",
    "\n",
    "# PERFORMANCE METRICS\n",
    "\n",
    "confmat = sklearn.metrics.confusion_matrix(test_labels, predictions)\n",
    "\n",
    "precision = confmat[1,1]/(confmat[1,1] + confmat[1,0])\n",
    "recall = confmat[1,1]/(confmat[1,1] + confmat[0,1])\n",
    "fScore = (2*precision*recall)/(recall+precision)\n",
    "ccr = (confmat[0,0] + confmat[1,1])/(sum(sum(confmat)))\n",
    "\n",
    "print(\"Precision = \",precision)\n",
    "print(\"Recall = \",recall)\n",
    "print(\"F_score = \",fScore)\n",
    "print(\"CCR = \",ccr)\n",
    "print()\n",
    "print(\"Confusion Matrix: \\n\", confmat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter 1.0 of 100\n",
      "Iter 2.0 of 100\n",
      "Iter 3.0 of 100\n",
      "Iter 4.0 of 100\n",
      "Iter 5.0 of 100\n",
      "Iter 6.0 of 100\n",
      "Iter 7.0 of 100\n",
      "Iter 8.0 of 100\n",
      "Iter 9.0 of 100\n",
      "Iter 10.0 of 100\n",
      "Iter 11.0 of 100\n",
      "Iter 12.0 of 100\n",
      "Iter 13.0 of 100\n",
      "Iter 14.0 of 100\n",
      "Iter 15.0 of 100\n",
      "Iter 16.0 of 100\n",
      "Iter 17.0 of 100\n",
      "Iter 18.0 of 100\n",
      "Iter 19.0 of 100\n",
      "Iter 20.0 of 100\n",
      "Iter 21.0 of 100\n",
      "Iter 22.0 of 100\n",
      "Iter 23.0 of 100\n",
      "Iter 24.0 of 100\n",
      "Iter 25.0 of 100\n",
      "Iter 26.0 of 100\n",
      "Iter 27.0 of 100\n",
      "Iter 28.0 of 100\n",
      "Iter 29.0 of 100\n",
      "Iter 30.0 of 100\n",
      "Iter 31.0 of 100\n",
      "Iter 32.0 of 100\n",
      "Iter 33.0 of 100\n",
      "Iter 34.0 of 100\n",
      "Iter 35.0 of 100\n",
      "Iter 36.0 of 100\n",
      "Iter 37.0 of 100\n",
      "Iter 38.0 of 100\n",
      "Iter 39.0 of 100\n",
      "Iter 40.0 of 100\n",
      "Iter 41.0 of 100\n",
      "Iter 42.0 of 100\n",
      "Iter 43.0 of 100\n"
     ]
    }
   ],
   "source": [
    "# TRAINING\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "clf = GaussianNB()\n",
    "\n",
    "for i in range(0, 10000):\n",
    "    if(i%100 == 0):\n",
    "        \n",
    "        print(\"Iter\", (i/100) + 1, \"of\", 100)\n",
    "    clf.partial_fit(train_feature_vectors_full[10*i:10*(i+1), :], train_labels[10*i:10*(i+1)], classes=np.array([0,1]), sample_weight=None)\n",
    "\n",
    "# PREDICTION\n",
    "predictions = clf.predict(test_feature_vectors_full)\n",
    "\n",
    "\n",
    "# PERFORMANCE METRICS\n",
    "\n",
    "confmat = sklearn.metrics.confusion_matrix(test_labels, predictions)\n",
    "\n",
    "precision = confmat[1,1]/(confmat[1,1] + confmat[1,0])\n",
    "recall = confmat[1,1]/(confmat[1,1] + confmat[0,1])\n",
    "fScore = (2*precision*recall)/(recall+precision)\n",
    "ccr = (confmat[0,0] + confmat[1,1])/(sum(sum(confmat)))\n",
    "\n",
    "print(\"Precision = \",precision)\n",
    "print(\"Recall = \",recall)\n",
    "print(\"F_score = \",fScore)\n",
    "print(\"CCR = \",ccr)\n",
    "print()\n",
    "print(\"Confusion Matrix: \\n\", confmat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
