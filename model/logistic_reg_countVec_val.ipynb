{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd, numpy as np\n",
    "import sklearn\n",
    "import scipy.sparse\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from scipy import sparse\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from bs4 import BeautifulSoup\n",
    "import re\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_data = pd.read_csv('../data/raw_data/train.csv')\n",
    "test_data = pd.read_csv('../data/raw_data/test.csv')\n",
    "\n",
    "train_labels=(train_data[\"Labels\"])\n",
    "test_labels = test_data[\"Labels\"]\n",
    "\n",
    "corpus_train = train_data[\"Comment\"]\n",
    "corpus_test = test_data[\"Comment\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Comment</th>\n",
       "      <th>Labels</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Thank you for understanding. I think very high...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>:Dear god this site is horrible.</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>\"::: Somebody will invariably try to add Relig...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>\" \\n\\n It says it right there that it IS a typ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>\" \\n\\n == Before adding a new product to the l...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             Comment  Labels\n",
       "0  Thank you for understanding. I think very high...       0\n",
       "1                   :Dear god this site is horrible.       0\n",
       "2  \"::: Somebody will invariably try to add Relig...       0\n",
       "3  \" \\n\\n It says it right there that it IS a typ...       0\n",
       "4  \" \\n\\n == Before adding a new product to the l...       0"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "pipeline = Pipeline([\n",
    "    ('cv', CountVectorizer(strip_accents='unicode',lowercase=True,stop_words='english', ngram_range=(1, 2))),\n",
    "    ('clf', LogisticRegression(multi_class='ovr'))\n",
    "])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import make_scorer, roc_auc_score\n",
    "\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "# tfidf_transformer = TfidfTransformer()\n",
    "parameters = {'clf__penalty':('l1','l2', None), 'clf__class_weight':(None, 'balanced'), 'clf__solver':('newton-cg', 'lbfgs')}\n",
    "grid = GridSearchCV(pipeline, parameters, scoring = make_scorer(roc_auc_score, average='macro'), cv=5, error_score=0.0, verbose=10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 12 candidates, totalling 60 fits\n",
      "[CV] clf__class_weight=None, clf__penalty=l1, clf__solver=newton-cg ..\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  clf__class_weight=None, clf__penalty=l1, clf__solver=newton-cg, score=0.0, total=  32.6s\n",
      "[CV] clf__class_weight=None, clf__penalty=l1, clf__solver=newton-cg ..\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:   32.6s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  clf__class_weight=None, clf__penalty=l1, clf__solver=newton-cg, score=0.0, total=  29.9s\n",
      "[CV] clf__class_weight=None, clf__penalty=l1, clf__solver=newton-cg ..\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:  1.0min remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  clf__class_weight=None, clf__penalty=l1, clf__solver=newton-cg, score=0.0, total=  30.9s\n",
      "[CV] clf__class_weight=None, clf__penalty=l1, clf__solver=newton-cg ..\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   3 out of   3 | elapsed:  1.6min remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  clf__class_weight=None, clf__penalty=l1, clf__solver=newton-cg, score=0.0, total=  29.5s\n",
      "[CV] clf__class_weight=None, clf__penalty=l1, clf__solver=newton-cg ..\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   4 out of   4 | elapsed:  2.1min remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  clf__class_weight=None, clf__penalty=l1, clf__solver=newton-cg, score=0.0, total=  33.5s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:  2.6min remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] clf__class_weight=None, clf__penalty=l1, clf__solver=lbfgs ......\n",
      "[CV]  clf__class_weight=None, clf__penalty=l1, clf__solver=lbfgs, score=0.0, total=  32.4s\n",
      "[CV] clf__class_weight=None, clf__penalty=l1, clf__solver=lbfgs ......\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   6 out of   6 | elapsed:  3.2min remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  clf__class_weight=None, clf__penalty=l1, clf__solver=lbfgs, score=0.0, total=  30.8s\n",
      "[CV] clf__class_weight=None, clf__penalty=l1, clf__solver=lbfgs ......\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   7 out of   7 | elapsed:  3.7min remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  clf__class_weight=None, clf__penalty=l1, clf__solver=lbfgs, score=0.0, total=  32.0s\n",
      "[CV] clf__class_weight=None, clf__penalty=l1, clf__solver=lbfgs ......\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   8 out of   8 | elapsed:  4.2min remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  clf__class_weight=None, clf__penalty=l1, clf__solver=lbfgs, score=0.0, total=  32.5s\n",
      "[CV] clf__class_weight=None, clf__penalty=l1, clf__solver=lbfgs ......\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   9 out of   9 | elapsed:  4.8min remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  clf__class_weight=None, clf__penalty=l1, clf__solver=lbfgs, score=0.0, total=  30.2s\n",
      "[CV] clf__class_weight=None, clf__penalty=l2, clf__solver=newton-cg ..\n",
      "[CV]  clf__class_weight=None, clf__penalty=l2, clf__solver=newton-cg, score=0.8299833448255289, total=11.8min\n",
      "[CV] clf__class_weight=None, clf__penalty=l2, clf__solver=newton-cg ..\n",
      "[CV]  clf__class_weight=None, clf__penalty=l2, clf__solver=newton-cg, score=0.8320851226804683, total= 7.3min\n",
      "[CV] clf__class_weight=None, clf__penalty=l2, clf__solver=newton-cg ..\n"
     ]
    }
   ],
   "source": [
    "grid.fit(corpus_train, train_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.76080052735964854"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_fit_time</th>\n",
       "      <th>mean_score_time</th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>mean_train_score</th>\n",
       "      <th>param_clf__class_weight</th>\n",
       "      <th>param_clf__penalty</th>\n",
       "      <th>param_clf__solver</th>\n",
       "      <th>params</th>\n",
       "      <th>rank_test_score</th>\n",
       "      <th>split0_test_score</th>\n",
       "      <th>...</th>\n",
       "      <th>split2_test_score</th>\n",
       "      <th>split2_train_score</th>\n",
       "      <th>split3_test_score</th>\n",
       "      <th>split3_train_score</th>\n",
       "      <th>split4_test_score</th>\n",
       "      <th>split4_train_score</th>\n",
       "      <th>std_fit_time</th>\n",
       "      <th>std_score_time</th>\n",
       "      <th>std_test_score</th>\n",
       "      <th>std_train_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.126878</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>None</td>\n",
       "      <td>l1</td>\n",
       "      <td>newton-cg</td>\n",
       "      <td>{'clf__class_weight': None, 'clf__penalty': 'l...</td>\n",
       "      <td>9</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.005123</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.122108</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>None</td>\n",
       "      <td>l1</td>\n",
       "      <td>lbfgs</td>\n",
       "      <td>{'clf__class_weight': None, 'clf__penalty': 'l...</td>\n",
       "      <td>9</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.004195</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>12.170704</td>\n",
       "      <td>0.030099</td>\n",
       "      <td>0.602469</td>\n",
       "      <td>0.728202</td>\n",
       "      <td>None</td>\n",
       "      <td>l1</td>\n",
       "      <td>liblinear</td>\n",
       "      <td>{'clf__class_weight': None, 'clf__penalty': 'l...</td>\n",
       "      <td>8</td>\n",
       "      <td>0.578125</td>\n",
       "      <td>...</td>\n",
       "      <td>0.606735</td>\n",
       "      <td>0.726709</td>\n",
       "      <td>0.620543</td>\n",
       "      <td>0.754021</td>\n",
       "      <td>0.655817</td>\n",
       "      <td>0.761084</td>\n",
       "      <td>0.562364</td>\n",
       "      <td>0.000544</td>\n",
       "      <td>0.035830</td>\n",
       "      <td>0.026134</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>15.591796</td>\n",
       "      <td>0.027935</td>\n",
       "      <td>0.748731</td>\n",
       "      <td>0.909980</td>\n",
       "      <td>None</td>\n",
       "      <td>l2</td>\n",
       "      <td>newton-cg</td>\n",
       "      <td>{'clf__class_weight': None, 'clf__penalty': 'l...</td>\n",
       "      <td>5</td>\n",
       "      <td>0.755214</td>\n",
       "      <td>...</td>\n",
       "      <td>0.756104</td>\n",
       "      <td>0.911711</td>\n",
       "      <td>0.745988</td>\n",
       "      <td>0.910371</td>\n",
       "      <td>0.742666</td>\n",
       "      <td>0.911294</td>\n",
       "      <td>0.956050</td>\n",
       "      <td>0.001205</td>\n",
       "      <td>0.005765</td>\n",
       "      <td>0.001472</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2.844136</td>\n",
       "      <td>0.025706</td>\n",
       "      <td>0.749201</td>\n",
       "      <td>0.908791</td>\n",
       "      <td>None</td>\n",
       "      <td>l2</td>\n",
       "      <td>lbfgs</td>\n",
       "      <td>{'clf__class_weight': None, 'clf__penalty': 'l...</td>\n",
       "      <td>4</td>\n",
       "      <td>0.755180</td>\n",
       "      <td>...</td>\n",
       "      <td>0.757808</td>\n",
       "      <td>0.911600</td>\n",
       "      <td>0.746821</td>\n",
       "      <td>0.906802</td>\n",
       "      <td>0.741379</td>\n",
       "      <td>0.909761</td>\n",
       "      <td>0.124904</td>\n",
       "      <td>0.000509</td>\n",
       "      <td>0.006259</td>\n",
       "      <td>0.001913</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>4.517600</td>\n",
       "      <td>0.027901</td>\n",
       "      <td>0.719302</td>\n",
       "      <td>0.795968</td>\n",
       "      <td>None</td>\n",
       "      <td>l2</td>\n",
       "      <td>liblinear</td>\n",
       "      <td>{'clf__class_weight': None, 'clf__penalty': 'l...</td>\n",
       "      <td>6</td>\n",
       "      <td>0.710758</td>\n",
       "      <td>...</td>\n",
       "      <td>0.733929</td>\n",
       "      <td>0.803316</td>\n",
       "      <td>0.734076</td>\n",
       "      <td>0.820811</td>\n",
       "      <td>0.701439</td>\n",
       "      <td>0.773936</td>\n",
       "      <td>0.193719</td>\n",
       "      <td>0.003286</td>\n",
       "      <td>0.012909</td>\n",
       "      <td>0.023032</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.122431</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>newton-cg</td>\n",
       "      <td>{'clf__class_weight': None, 'clf__penalty': No...</td>\n",
       "      <td>9</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.004945</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.119220</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>lbfgs</td>\n",
       "      <td>{'clf__class_weight': None, 'clf__penalty': No...</td>\n",
       "      <td>9</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.002178</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.117854</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>liblinear</td>\n",
       "      <td>{'clf__class_weight': None, 'clf__penalty': No...</td>\n",
       "      <td>9</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.001395</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.117963</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>balanced</td>\n",
       "      <td>l1</td>\n",
       "      <td>newton-cg</td>\n",
       "      <td>{'clf__class_weight': 'balanced', 'clf__penalt...</td>\n",
       "      <td>9</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.003009</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.118230</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>balanced</td>\n",
       "      <td>l1</td>\n",
       "      <td>lbfgs</td>\n",
       "      <td>{'clf__class_weight': 'balanced', 'clf__penalt...</td>\n",
       "      <td>9</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.002800</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>820.538170</td>\n",
       "      <td>0.030657</td>\n",
       "      <td>0.680842</td>\n",
       "      <td>0.836020</td>\n",
       "      <td>balanced</td>\n",
       "      <td>l1</td>\n",
       "      <td>liblinear</td>\n",
       "      <td>{'clf__class_weight': 'balanced', 'clf__penalt...</td>\n",
       "      <td>7</td>\n",
       "      <td>0.688247</td>\n",
       "      <td>...</td>\n",
       "      <td>0.675530</td>\n",
       "      <td>0.837968</td>\n",
       "      <td>0.688800</td>\n",
       "      <td>0.840156</td>\n",
       "      <td>0.674274</td>\n",
       "      <td>0.836658</td>\n",
       "      <td>75.952321</td>\n",
       "      <td>0.000577</td>\n",
       "      <td>0.006351</td>\n",
       "      <td>0.004210</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>27.227202</td>\n",
       "      <td>0.029512</td>\n",
       "      <td>0.760801</td>\n",
       "      <td>0.933798</td>\n",
       "      <td>balanced</td>\n",
       "      <td>l2</td>\n",
       "      <td>newton-cg</td>\n",
       "      <td>{'clf__class_weight': 'balanced', 'clf__penalt...</td>\n",
       "      <td>1</td>\n",
       "      <td>0.756498</td>\n",
       "      <td>...</td>\n",
       "      <td>0.760648</td>\n",
       "      <td>0.933756</td>\n",
       "      <td>0.754541</td>\n",
       "      <td>0.933755</td>\n",
       "      <td>0.766368</td>\n",
       "      <td>0.932475</td>\n",
       "      <td>4.523718</td>\n",
       "      <td>0.002088</td>\n",
       "      <td>0.004800</td>\n",
       "      <td>0.000952</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>3.282049</td>\n",
       "      <td>0.029911</td>\n",
       "      <td>0.759871</td>\n",
       "      <td>0.927649</td>\n",
       "      <td>balanced</td>\n",
       "      <td>l2</td>\n",
       "      <td>lbfgs</td>\n",
       "      <td>{'clf__class_weight': 'balanced', 'clf__penalt...</td>\n",
       "      <td>2</td>\n",
       "      <td>0.754535</td>\n",
       "      <td>...</td>\n",
       "      <td>0.758573</td>\n",
       "      <td>0.932697</td>\n",
       "      <td>0.754822</td>\n",
       "      <td>0.926542</td>\n",
       "      <td>0.766237</td>\n",
       "      <td>0.924243</td>\n",
       "      <td>0.164480</td>\n",
       "      <td>0.003278</td>\n",
       "      <td>0.004989</td>\n",
       "      <td>0.002922</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>12.544415</td>\n",
       "      <td>0.028173</td>\n",
       "      <td>0.751477</td>\n",
       "      <td>0.917738</td>\n",
       "      <td>balanced</td>\n",
       "      <td>l2</td>\n",
       "      <td>liblinear</td>\n",
       "      <td>{'clf__class_weight': 'balanced', 'clf__penalt...</td>\n",
       "      <td>3</td>\n",
       "      <td>0.746709</td>\n",
       "      <td>...</td>\n",
       "      <td>0.755833</td>\n",
       "      <td>0.926344</td>\n",
       "      <td>0.749595</td>\n",
       "      <td>0.924421</td>\n",
       "      <td>0.756682</td>\n",
       "      <td>0.901636</td>\n",
       "      <td>1.535630</td>\n",
       "      <td>0.002134</td>\n",
       "      <td>0.004020</td>\n",
       "      <td>0.009941</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>0.122323</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>balanced</td>\n",
       "      <td>None</td>\n",
       "      <td>newton-cg</td>\n",
       "      <td>{'clf__class_weight': 'balanced', 'clf__penalt...</td>\n",
       "      <td>9</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.003518</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>0.117949</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>balanced</td>\n",
       "      <td>None</td>\n",
       "      <td>lbfgs</td>\n",
       "      <td>{'clf__class_weight': 'balanced', 'clf__penalt...</td>\n",
       "      <td>9</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000879</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>0.118606</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>balanced</td>\n",
       "      <td>None</td>\n",
       "      <td>liblinear</td>\n",
       "      <td>{'clf__class_weight': 'balanced', 'clf__penalt...</td>\n",
       "      <td>9</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.001868</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>18 rows Ã— 23 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    mean_fit_time  mean_score_time  mean_test_score  mean_train_score  \\\n",
       "0        0.126878         0.000000         0.000000          0.000000   \n",
       "1        0.122108         0.000000         0.000000          0.000000   \n",
       "2       12.170704         0.030099         0.602469          0.728202   \n",
       "3       15.591796         0.027935         0.748731          0.909980   \n",
       "4        2.844136         0.025706         0.749201          0.908791   \n",
       "5        4.517600         0.027901         0.719302          0.795968   \n",
       "6        0.122431         0.000000         0.000000          0.000000   \n",
       "7        0.119220         0.000000         0.000000          0.000000   \n",
       "8        0.117854         0.000000         0.000000          0.000000   \n",
       "9        0.117963         0.000000         0.000000          0.000000   \n",
       "10       0.118230         0.000000         0.000000          0.000000   \n",
       "11     820.538170         0.030657         0.680842          0.836020   \n",
       "12      27.227202         0.029512         0.760801          0.933798   \n",
       "13       3.282049         0.029911         0.759871          0.927649   \n",
       "14      12.544415         0.028173         0.751477          0.917738   \n",
       "15       0.122323         0.000000         0.000000          0.000000   \n",
       "16       0.117949         0.000000         0.000000          0.000000   \n",
       "17       0.118606         0.000000         0.000000          0.000000   \n",
       "\n",
       "   param_clf__class_weight param_clf__penalty param_clf__solver  \\\n",
       "0                     None                 l1         newton-cg   \n",
       "1                     None                 l1             lbfgs   \n",
       "2                     None                 l1         liblinear   \n",
       "3                     None                 l2         newton-cg   \n",
       "4                     None                 l2             lbfgs   \n",
       "5                     None                 l2         liblinear   \n",
       "6                     None               None         newton-cg   \n",
       "7                     None               None             lbfgs   \n",
       "8                     None               None         liblinear   \n",
       "9                 balanced                 l1         newton-cg   \n",
       "10                balanced                 l1             lbfgs   \n",
       "11                balanced                 l1         liblinear   \n",
       "12                balanced                 l2         newton-cg   \n",
       "13                balanced                 l2             lbfgs   \n",
       "14                balanced                 l2         liblinear   \n",
       "15                balanced               None         newton-cg   \n",
       "16                balanced               None             lbfgs   \n",
       "17                balanced               None         liblinear   \n",
       "\n",
       "                                               params  rank_test_score  \\\n",
       "0   {'clf__class_weight': None, 'clf__penalty': 'l...                9   \n",
       "1   {'clf__class_weight': None, 'clf__penalty': 'l...                9   \n",
       "2   {'clf__class_weight': None, 'clf__penalty': 'l...                8   \n",
       "3   {'clf__class_weight': None, 'clf__penalty': 'l...                5   \n",
       "4   {'clf__class_weight': None, 'clf__penalty': 'l...                4   \n",
       "5   {'clf__class_weight': None, 'clf__penalty': 'l...                6   \n",
       "6   {'clf__class_weight': None, 'clf__penalty': No...                9   \n",
       "7   {'clf__class_weight': None, 'clf__penalty': No...                9   \n",
       "8   {'clf__class_weight': None, 'clf__penalty': No...                9   \n",
       "9   {'clf__class_weight': 'balanced', 'clf__penalt...                9   \n",
       "10  {'clf__class_weight': 'balanced', 'clf__penalt...                9   \n",
       "11  {'clf__class_weight': 'balanced', 'clf__penalt...                7   \n",
       "12  {'clf__class_weight': 'balanced', 'clf__penalt...                1   \n",
       "13  {'clf__class_weight': 'balanced', 'clf__penalt...                2   \n",
       "14  {'clf__class_weight': 'balanced', 'clf__penalt...                3   \n",
       "15  {'clf__class_weight': 'balanced', 'clf__penalt...                9   \n",
       "16  {'clf__class_weight': 'balanced', 'clf__penalt...                9   \n",
       "17  {'clf__class_weight': 'balanced', 'clf__penalt...                9   \n",
       "\n",
       "    split0_test_score       ...         split2_test_score  split2_train_score  \\\n",
       "0            0.000000       ...                  0.000000            0.000000   \n",
       "1            0.000000       ...                  0.000000            0.000000   \n",
       "2            0.578125       ...                  0.606735            0.726709   \n",
       "3            0.755214       ...                  0.756104            0.911711   \n",
       "4            0.755180       ...                  0.757808            0.911600   \n",
       "5            0.710758       ...                  0.733929            0.803316   \n",
       "6            0.000000       ...                  0.000000            0.000000   \n",
       "7            0.000000       ...                  0.000000            0.000000   \n",
       "8            0.000000       ...                  0.000000            0.000000   \n",
       "9            0.000000       ...                  0.000000            0.000000   \n",
       "10           0.000000       ...                  0.000000            0.000000   \n",
       "11           0.688247       ...                  0.675530            0.837968   \n",
       "12           0.756498       ...                  0.760648            0.933756   \n",
       "13           0.754535       ...                  0.758573            0.932697   \n",
       "14           0.746709       ...                  0.755833            0.926344   \n",
       "15           0.000000       ...                  0.000000            0.000000   \n",
       "16           0.000000       ...                  0.000000            0.000000   \n",
       "17           0.000000       ...                  0.000000            0.000000   \n",
       "\n",
       "    split3_test_score  split3_train_score  split4_test_score  \\\n",
       "0            0.000000            0.000000           0.000000   \n",
       "1            0.000000            0.000000           0.000000   \n",
       "2            0.620543            0.754021           0.655817   \n",
       "3            0.745988            0.910371           0.742666   \n",
       "4            0.746821            0.906802           0.741379   \n",
       "5            0.734076            0.820811           0.701439   \n",
       "6            0.000000            0.000000           0.000000   \n",
       "7            0.000000            0.000000           0.000000   \n",
       "8            0.000000            0.000000           0.000000   \n",
       "9            0.000000            0.000000           0.000000   \n",
       "10           0.000000            0.000000           0.000000   \n",
       "11           0.688800            0.840156           0.674274   \n",
       "12           0.754541            0.933755           0.766368   \n",
       "13           0.754822            0.926542           0.766237   \n",
       "14           0.749595            0.924421           0.756682   \n",
       "15           0.000000            0.000000           0.000000   \n",
       "16           0.000000            0.000000           0.000000   \n",
       "17           0.000000            0.000000           0.000000   \n",
       "\n",
       "    split4_train_score  std_fit_time  std_score_time  std_test_score  \\\n",
       "0             0.000000      0.005123        0.000000        0.000000   \n",
       "1             0.000000      0.004195        0.000000        0.000000   \n",
       "2             0.761084      0.562364        0.000544        0.035830   \n",
       "3             0.911294      0.956050        0.001205        0.005765   \n",
       "4             0.909761      0.124904        0.000509        0.006259   \n",
       "5             0.773936      0.193719        0.003286        0.012909   \n",
       "6             0.000000      0.004945        0.000000        0.000000   \n",
       "7             0.000000      0.002178        0.000000        0.000000   \n",
       "8             0.000000      0.001395        0.000000        0.000000   \n",
       "9             0.000000      0.003009        0.000000        0.000000   \n",
       "10            0.000000      0.002800        0.000000        0.000000   \n",
       "11            0.836658     75.952321        0.000577        0.006351   \n",
       "12            0.932475      4.523718        0.002088        0.004800   \n",
       "13            0.924243      0.164480        0.003278        0.004989   \n",
       "14            0.901636      1.535630        0.002134        0.004020   \n",
       "15            0.000000      0.003518        0.000000        0.000000   \n",
       "16            0.000000      0.000879        0.000000        0.000000   \n",
       "17            0.000000      0.001868        0.000000        0.000000   \n",
       "\n",
       "    std_train_score  \n",
       "0          0.000000  \n",
       "1          0.000000  \n",
       "2          0.026134  \n",
       "3          0.001472  \n",
       "4          0.001913  \n",
       "5          0.023032  \n",
       "6          0.000000  \n",
       "7          0.000000  \n",
       "8          0.000000  \n",
       "9          0.000000  \n",
       "10         0.000000  \n",
       "11         0.004210  \n",
       "12         0.000952  \n",
       "13         0.002922  \n",
       "14         0.009941  \n",
       "15         0.000000  \n",
       "16         0.000000  \n",
       "17         0.000000  \n",
       "\n",
       "[18 rows x 23 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = pd.DataFrame.from_dict(grid.cv_results_)\n",
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(memory=None,\n",
       "     steps=[('tfidf', TfidfTransformer(norm=None, smooth_idf=True, sublinear_tf=False,\n",
       "         use_idf=False)), ('clf', LogisticRegression(C=1.0, class_weight='balanced', dual=False,\n",
       "          fit_intercept=True, intercept_scaling=1, max_iter=100,\n",
       "          multi_class='ovr', n_jobs=None, penalty='l2', random_state=None,\n",
       "          solver='newton-cg', tol=0.0001, verbose=0, warm_start=False))])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "def accuracy_plot(a):\n",
    "    \n",
    "\n",
    "    clf = LogisticRegression(C=1.0, class_weight=a['clf__class_weight'], dual=False,\n",
    "              fit_intercept=True, intercept_scaling=1, max_iter=100,\n",
    "              multi_class='ovr', n_jobs=None, penalty=a['clf__penalty'], random_state=None,\n",
    "              solver=a['clf__solver'], tol=0.0001, verbose=0, warm_start=False)\n",
    "\n",
    "    clf.fit(train_feature_vectors_sparse, train_labels)\n",
    "\n",
    "    predictions = clf.predict(test_feature_vectors_sparse)\n",
    "    confmat = confusion_matrix(test_labels, predictions)\n",
    "\n",
    "    precision = confmat[1,1]/(confmat[1,1] + confmat[1,0])\n",
    "    recall = confmat[1,1]/(confmat[1,1] + confmat[0,1])\n",
    "    fScore = f1_score(test_labels, predictions, average='macro')\n",
    "    ccr = (confmat[0,0] + confmat[1,1])/(sum(sum(confmat)))\n",
    "    roc_auc = roc_auc_score(test_labels, predictions)\n",
    "    print(\"Precision = \",precision)\n",
    "    print(\"Recall = \",recall)\n",
    "    print(\"F_score = \",fScore)\n",
    "    print(\"CCR = \",ccr)\n",
    "    print(\"ROC_AUC = \", roc_auc)\n",
    "    print()\n",
    "    print(\"Confusion Matrix: \\n\", confmat)\n",
    "    print()\n",
    "    return [precision,recall, fScore, ccr, roc_auc]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision =  0.810739144846\n",
      "Recall =  0.719094517125\n",
      "F_score =  0.866726027733\n",
      "CCR =  0.948749370489\n",
      "ROC_AUC =  0.887521769076\n",
      "\n",
      "Confusion Matrix: \n",
      " [[51625  1911]\n",
      " [ 1142  4892]]\n",
      "\n",
      "Precision =  0.814219423268\n",
      "Recall =  0.717959959082\n",
      "F_score =  0.86717707518\n",
      "CCR =  0.948782944435\n",
      "ROC_AUC =  0.889084457599\n",
      "\n",
      "Confusion Matrix: \n",
      " [[51606  1930]\n",
      " [ 1121  4913]]\n",
      "\n",
      "Precision =  0.819522704674\n",
      "Recall =  0.700127424607\n",
      "F_score =  0.862446157434\n",
      "CCR =  0.946164176599\n",
      "ROC_AUC =  0.889980270448\n",
      "\n",
      "Confusion Matrix: \n",
      " [[51418  2118]\n",
      " [ 1089  4945]]\n",
      "\n",
      "Precision =  0.682797480941\n",
      "Recall =  0.864093959732\n",
      "F_score =  0.869586743804\n",
      "CCR =  0.956991774383\n",
      "ROC_AUC =  0.83534673808\n",
      "\n",
      "Confusion Matrix: \n",
      " [[52888   648]\n",
      " [ 1914  4120]]\n",
      "\n",
      "Precision =  0.681968843222\n",
      "Recall =  0.863045302013\n",
      "F_score =  0.869077714701\n",
      "CCR =  0.95682390465\n",
      "ROC_AUC =  0.834885721671\n",
      "\n",
      "Confusion Matrix: \n",
      " [[52883   653]\n",
      " [ 1919  4115]]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "fsc = []\n",
    "prec = []\n",
    "recall = []\n",
    "ccr = []\n",
    "roc_auc = []\n",
    "for i in range (1,6):\n",
    "    ind = list((a[\"rank_test_score\"] == i)).index(True)\n",
    "    params = a['params'][ind]\n",
    "    res = accuracy_plot(params)\n",
    "    fsc.append(res[2])\n",
    "    prec.append(res[0])\n",
    "    recall.append(res[1])\n",
    "    ccr.append(res[3])\n",
    "    roc_auc.append(res[4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYsAAAD8CAYAAACGsIhGAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDIuMS4wLCBo\ndHRwOi8vbWF0cGxvdGxpYi5vcmcvpW3flQAAIABJREFUeJzt3Xd8FNX6+PHPkx4IPfQQCArSCRDa\nRWzYFRQpwrVfELGg2L5XxIKoV2xcRfAKKKJ4FSnqDxEVG+ilCKFIlSIECUWQHiF1z++P2ZBN3U2Z\nnWzyvF+vee3uzJmZZwdynp0zM+eIMQallFKqKEFOB6CUUqr802ShlFLKK00WSimlvNJkoZRSyitN\nFkoppbzSZKGUUsorTRZKKaW80mShlFLKK00WSimlvApxOoCyEh0dbZo1a+Z0GEopFVDWrFnzpzGm\nrrdyFSZZNGvWjMTERKfDUEqpgCIie3wpp81QSimlvNJkoZRSyitNFkoppbzSZKGUUsorTRZKKaW8\n0mShlFLKK00WSimlvKowz1kopQKPMYask1mk7UsjbX8a6fvTSdufhuu0K6eQ5HkFRKTQZdnvz5Yp\nqFxR2yqgXJHbKqhcEduyI/7QeqFE943GTposlFK2yDqdlSsBpO9PJ21fns95E0O27MrQ+DXkgFWt\nezVNFkqp8sWV7iL9YO4KP31fer7EkHk8M9+6QZFBhDUKI7xxONUSqlGnUR3CG4Vb8xqFE9Y4jPCG\n4QRXDS50/8a4M0h2IjFFLCug3NkyhWwjX7kituUtHp/2WQbxS6jnqYk9bE0WInIl8DoQDLxtjJmQ\nZ3lTYAZQFzgK3GyMSXYvywI2uov+bozpZ2esSlV2JsuQfji9yASQti+NjMMZ+daVECGsoZUEqrSq\nQq1LauVOAO6EEFIjJHfzSgkU2NSTvaygmapM2JYsRCQYmAJcBiQDq0VkgTFmi0exV4D3jTHvicgl\nwAvALe5lZ4wx8XbFp1RlYYwh81hmkQkgbX8a6QfTISvPygJh9cOsij8mnGrdquWcCTTOOSMIjQ5F\ngrSirsjsPLPoBuw0xuwCEJHZwHWAZ7JoAzzofv8D8JmN8ShV4WSmZBadANzzTFr+xv+Q2iFnK/6q\nbavmSwBhjcIIqx9GUKjeNKnsTRaNgb0en5OB7nnK/AIMwGqq6g9UE5E6xpgjQISIJAKZwARjTL5E\nIiIjgBEAsbGxJQoy81Qmu/65q3grleCiW652Rhv3U+x1SngBUUIECROCwoOs17CgXO8l3P3qLuP5\n/myZopaFSqmbKwJZVmoW6QfSi0wA6fvTyTqV91QAgqoGEd44nPBG4VTvWT1fU1B4o3DCGoYRHFn4\ndQGl8rIzWRT0l563anoEmCwitwM/AvuwkgNArDFmv4g0B74XkY3GmN9ybcyYacA0gISEhBJVe640\nF4fnHS7+iiWpx0qwTokqzOKuUtzyxmrfdqW5MOkGV7orf/NFGShO4iluovKpvLdtlaDZxZXpIuOP\njCITQNr+NDKP5L84LGFytsKPah9F2JV5EoD7NaS63reiyp6d/6uSgSYen2OA/Z4FjDH7gRsARCQK\nGGCMOeGxDGPMLhFZAnQCciWLshAWHUavQ73KerOVjsmykoZJt5KI5/vshOL53qSVXfmsU1lk/JlR\n5DZMhg33YAbjc+LJPGE1F6X/kZ7/J1MQhDWwKvqIuAhqnF8jXwIIbxxOSO3SXxxWqqTsTBargRYi\nEod1xjAE+LtnARGJBo4aY1zAGKw7oxCRWsBpY0yau0wv4CUbY1WlJMFiNWtEOh1JwYwxOYnH3wkt\n1UVY3TCi4qPynwk0DiesXhgSrElAlW+2JQtjTKaI3Ad8jXXr7AxjzGYRGQ8kGmMWABcBL4iIwWqG\nute9emtgqoi4sLokmZDnLiqlikVErF/94XqxVqmSkBJdeC2HEhISjA6rqpRSxSMia4wxCd7K6c8s\npZRSXmmyUEop5ZUmC6WUUl5pslBKKeWVJgullFJeabJQSinllSYLpZRSXmmyUEop5ZUmC6WUUl5p\nslBKKeWVJgullFJeabJQSinllSYLpZRSXmmyUEop5ZUmC6WUUl5pslBKKeWVJgullFJeabJQSinl\nlSYLpZRSXmmyUEop5ZUmC6WUUl5pslBKKeWVJgullFJeabJQSinllSYLpZRSXmmyUEop5ZUmC6WU\nUl7ZmixE5EoR2SYiO0XksQKWNxWR70Rkg4gsEZEYj2W3icgO93SbnXEqpZQqmm3JQkSCgSnAVUAb\nYKiItMlT7BXgfWNMB2A88IJ73drA00B3oBvwtIjUsitWpZRSRbPzzKIbsNMYs8sYkw7MBq7LU6YN\n8J37/Q8ey68AvjHGHDXGHAO+Aa60MVallFJFsDNZNAb2enxOds/z9AswwP2+P1BNROr4uC4iMkJE\nEkUk8fDhw2UWuFJKqdzsTBZSwDyT5/MjwIUisg64ENgHZPq4LsaYacaYBGNMQt26dUsbr1JKqUKE\n2LjtZKCJx+cYYL9nAWPMfuAGABGJAgYYY06ISDJwUZ51l9gYq1JKqSLYeWaxGmghInEiEgYMARZ4\nFhCRaBHJjmEMMMP9/mvgchGp5b6wfbl7nlJKKQfYliyMMZnAfViV/FZgjjFms4iMF5F+7mIXAdtE\nZDtQH3jeve5R4FmshLMaGO+ep5RSygFiTL5LAQEpISHBJCYmOh2GUkoFFBFZY4xJ8FbOzmsWSvmF\n9YPHhTEujMk6+z73a+Hz889zAQXPL872s+eBoXr1HkRENPXzkVGq7GiycIgxxl1RZeaarEoqM8+U\nd54vZQralm/r+bYt+ytbX7cfCERCadhwOE2bjiU8PN9d4EqVe5U+WWRmnmL37sdLVZn6VsHnnlee\nKjmRkLMTBOf6LJL3c/a8YCAI6/6EII/PIYjknp/z3vO14Pn5t1uadQqfX5ztl/Z7uFzpHDgw3T3N\noHHje4iNfYywsHp2/9MqVWYqfbIwJp0//viwgEoxfyXpWZEGBUV4qUx931Zx1vNtW76tl1OhFfRY\niypL1aq9SZMmj7Jnz3iSk19n//5pxMTcT5MmjxAaWtvp8JTySi9wK+Vnp09vIylpHIcOzSY4uDpN\nmjxCTMwDhIRUdzo0VQn5eoFbuyhXys+qVDmPNm0+IiHhF2rVuoSkpKdYubI5v//+MllZp50OT6kC\nabJQyiFRUR1o1+5TOndeRfXqXdm16/9YubI5yclv4HKlOR2eUrloslDKYdWrd6VDhy+Jj/+JKlVa\nsXPn/fz8cwv275+Oy5XhdHhKAZoslCo3atY8n/j4H+jQ4RvCwhqxffsIVq1qzcGDH7hvLVbKOZos\nlCpHRITatS+lc+cVtGv3OcHBUfz66y2sXt2eQ4fmuZ8tUcr/NFkoVQ6JCNHR15KQsJY2beYCsGXL\nINas6cKffy6kotzFqAKHJgulyjGRIOrVG0jXrhtp1WoWmZmn2LSpL2vX9uTo0W81aSi/0WShVAAQ\nCaZBg5vp1m0rLVtOJz19Pxs2XMb69Rdz/Pj/nA5PVQKaLJQKIEFBoTRqNJzu3Xdw7rlvcObMNtav\n782GDVdx8qQ+lKrso8lCqQAUFBROTMx9dO/+G82bv8TJk6tZu7Yrmzb1JyVlo9PhqQpIu/tQqgLI\nzDxJcvLr7N37CllZp6hX70aaNRtHlSrnOR1aDmMgJQWOHoVjx3Kmgj6np4NIzhQUVPRnX8qUZJ1A\nKVOnDlx0UYn+WXzt7kOThVIVSEbGUfbufZXk5Ndxuc7QoMGtNG36FJGRcWWzA2Pg9GnvlX1Bn48f\nh8zMwrcdEgK1allTeLi1L8/J5Sr6sz/KlFfdu8PKlSVaVZOFr06ehPvuy/+fpaCpoP9U5bWsnfsH\niIiAqlWtKSqq4NeilhVUJjzc+qWkSi09/RC//z6BffveBLJo2HA4sbFjiYiIsQqkppaswj92zPrV\nX5igIKhZM6fSr1274PcFfY6KCox/f1+Tjj+TWUQEtGhRoq+jI+X5KiMDfvop/6met1O/sigbFFS8\nsmW9/+LGmv0eIC3NalL466+c1337cn9OSYGsYjx5HBxcumRT2LIqVaz4K5qMjEIr9LCjRzn3mKFJ\nWl/2nJfIgYypHNgzlcbfVCF2VhZhB1OL3naNGrkr9HbtfKvwq1evmMfak+ffRCWiZxbKPsZYv0Lz\nJpCCXn0p41k21Utll1eVKiVPNkW9hoaW7hhlZVnNM8X9dX/smHU8ihIVdbZCPxMXwZ5LD3Cw9V6C\nXMHEHOxFk7+uJbRGTP5f/zVqWInbIa++Cl99ZdXFwcHFfy3JOoG8zdKejOmZhXKeiNW0FB5uVUJl\nKTPTajsvbfI5fDj/esX5ARUa6luySUsruPI/ebLo7UdG5v4F36wZdOrkvXmnZs1ciSwSaAXEnt5G\nUtIz/B4ym33B62jS5GFiYkaXm7E0Fi+GRx6B1q2tkxSXy8qnvr76WrYiEYGePWHZMpv3o2cWSnkw\nBs6cKVnyKWpZdsL0tf0++3N4uC1fMyVlI0lJT/Hnn58RElKb2Nh/0rjxvQQHV7Vlf77FBO3bW195\n/XqrGd4uLlfZJyB/b8tzm40bw8iRJTsWemahVEmIWE1WVao4HYmtoqLa067dp5w8mUhS0pPs2vVP\n9u6dSNOmY2nUaARBQfYkqaI8+SQkJcGPP9qbKCDncmGI1oA+q1xXaJRSuVSvnlAuxtJYuRJefx3u\nvht69/bbblUxaLJQSp0dS6Njx289xtJoxcGDs7B7LI30dBg+3GpKmTDB1l2pUtBkoZQCQESoVasP\nnTuvoH37hYSEVOfXX291j6UxF7vG0njhBdi8Gd56y7qorconW5OFiFwpIttEZKeIPFbA8lgR+UFE\n1onIBhG52j2/mYicEZH17uktO+NUSuUQEerUuYYuXdZ4jKUx2JaxNDZvhuefh6FD4Zprymyzyga2\n3Q0lIsHAduAyIBlYDQw1xmzxKDMNWGeM+Y+ItAEWGWOaiUgzYKExpp2v+9O7oZSyhzFZ/PHHRyQl\njSM19TeqVetOXNxz1KrVBynFTf5ZWdCrF+zcCVu3Qt26ZRi08pmvd0PZeWbRDdhpjNlljEkHZgPX\n5SljgOwTzxrAfhvjUUqVgF1jaUyeDD//bF3Y1kRR/tmZLBoDez0+J7vneRoH3CwiycAiYJTHsjh3\n89RSEdH7I5RyWGFjafzyy5WcPLm6WNtKSoLHH4erroK//92eeFXZsjNZFHR+mrfNaygw0xgTA1wN\nzBKRIOAAEGuM6QQ8BHwoIvkufYnICBFJFJHEw4cPl3H4SqmC5B1L49SpRNau7cbGjdeTkrLB6/rG\nwIgR1nMOb70VGH0HKnuTRTLQxONzDPmbmYYBcwCMMSuACCDaGJNmjDninr8G+A1omXcHxphpxpgE\nY0xCXT2PVcqvgoOrEBv7KD167KJZs/EcP/4DiYkd2bx5CH/99Wuh673/PnzzjXWbbGysHwNWpWJn\nslgNtBCROBEJA4YAC/KU+R3oAyAirbGSxWERqeu+QI6INAdaALtsjFUpVUIhIdVp1uxJevTYTWzs\n4xw5spDVq9uydevtnDmzO1fZP/6ABx+0LmzffbdDAasSsS1ZGGMygfuAr4GtwBxjzGYRGS8i/dzF\nHgbuFJFfgI+A2411e9YFwAb3/HnASGPMUbtiVUqVXmhobZo3f54ePXYREzOaQ4dms2pVS7Zvv5vU\n1GQA7r/f6irr7bcrXQ/fAU87ElRK2SItbR979vyLAwemA0Gkpt7N0KGP8fDD9Rk71unoVLbycOus\nUqoSCw9vTMuWU+jWbTu1av2d0NBJfPRRcwYPHkNGhjYUBBpNFkopW0VGNmPKlBncccdWqla9jn37\nXmTlyjiSksaTmellPA9VbviULETkARGpLpZ3RGStiFxud3BKqcC3ZAlMmwaDBrXk/PM/JCHhF2rV\n6kNS0tOsXBnH77+/RFbWX06Hqbzw9cziH8aYk8DlQF3gDkD7h1RKFenMGbjzTmjeHMaPt+ZZY2l8\nQufOq6levTu7dv2TlSvPITl5EllZxRwuV/mNr0N/ZD82czXwrjHmFylNpzBKqUph3Dir76fvvss/\nnpQ1lsYiTpxYxu7dT7Bz5wPs3fsyTZs+SXR0f6y75wUQdx9UkudzUBHLPN+rsuDT3VAi8i5WVx1x\nQEcgGFhijOlib3i+07uhlCpf1qyB7t3h9tutW2WLYozh+PHv2b37CU6eXFnGkRSWSIIKXZZ3eeEJ\nKchLsirtPnxJiEFUqdKGli2nlOzolPGwqsOAeGCXMea0iNTBaopSSql8MjJg2DCoVw9eecV7+eyx\nNGrWvIRjx77h9OlfAePuDj1nyvnsKmJZ9mdXEcusbTi/j9zbKMk+jMmyfYAq8D1ZXAd8b4w54f6c\nBTQHvHcEo5SqdF55BX75BT75BGrW9H09EaF27cupXVvvnylvfL3A/bRHosAYcxx42p6QlFKBbNs2\neOYZGDAA+vd3OhpVVnxNFgWV8/WsRClVSbhc1njakZHWeBWq4vC1wk8UkYnAFKzGslHAGtuiUkoF\npKlT4X//gxkzoEEDp6NRZcnXM4tRQDrwMTAXSAXutSsopVTgSU6Gf/4TLr3UugNKVSw+nVkYY/4C\nHrM5FqVUgDIGRo60xtWeOlUHNKqIikwWIvKaMWa0iHxO/lHuMMb0K2A1pVQlM3s2fPEFTJxoPa2t\nKh5vZxaz3K8+3CmtlKqM/vzTGqeiWzfrVVVMRSYLY8wa94h1dxpjbvZTTEqpAPLgg3D8uPWUdnCw\n09Eou3i9ZmGMyXIPcxpmjEn3R1BKlUfGGFIzUzmVfopTaac4lX6KlPSUs+89X1PSU6z36ac4nXGa\nf8T/g2taXuP0VyhzX34JH3wATz0F7ds7HY2yk6+3ziYBy0RkAXC2L2FjzEQ7glKqLGRX7mcr7jyV\neoEVvZcEkOVjtwoRIRFUC6tGVFgUZzLPsGjHIlYOW0nHBh1t/tb+c+oU3HUXtG4Njz/udDTKbr4m\ni/3uKQio5p5XMcZjVeWGMYa0rLSCf6EXVdEXUdbXyj08OJxq4dWoFlaNauFWJV8rohaxNWKteR7z\ns997vkaFReV6Hxocenbbh/46RKepnRgwZwCJIxKpGVGM/i/Ksccft26XXbYMwsOdjkbZzddkscUY\nM9dzhogMsiEeFUCyK/eCfokX+us8o+hmm0xXpk/7Dg8Oz1VBVwuvRs2ImjSp0SSnQs9TqRdV0XtW\n7mWtXtV6zB00lwtnXshtn93Gpzd+SpAE9iCVy5bBlClw333Qs6fT0Sh/8LWL8rXGmM7e5jmpsndR\nbowhPSudM5lnSM1MJTUzlTMZ1vui5mV/zjXPh20Ut3IPCw4r9Jf42dfC5uep6KPCoggLDrP5iJa9\nST9P4oGvHuCFPi/w2PmB+9hSaip06gSnT8PmzRAV5XREqjTKpItyEbkKa8CjxiIyyWNRdcC3WqKS\nyXJl5a98C6qQi5iXq2L2cRupmamYUrQMhgSFEBkSSURIBJGh1mtESMTZebUja5+dFxESQVRo/kq9\noIo+e14gVu5lbVS3UaxIXsHY78fSrXE3Lom7xOmQSuT55+HXX+GrrzRRVCbemqH2A4lAP3L3BXUK\neNCuoPzpdMZpPtr4kW+/qIuq1N3zMlwZpYonbyXtWXlHhkRSM6Jmzrzg3MsKKl/YPM+EEBESQUiQ\n9gtpNxFhet/p/HLwF4bMG8K6u9bRuHpjp8Mqlg0bYMIEuOUWuOIKp6NR/uRrM1QoVmKJNcZssz2q\nEihpM9Thvw5T75V6ueYFSRCRIZEF/sIucF5Ry4qYl7cyDwsOC/i2bOXdr3/+StfpXWlfrz1Lbl8S\nMGddmZnW9Yk9e2DrVqhTx+mIVFko65HyrsR6ijsMiBOReGB8Rejuo3ZkbfaM3pOr8rbzYqdSraJb\n8U6/d7hx3o08uvhRXr/qdadD8snrr0NiotW1hyaKysfXZDEO6AYsATDGrBeRZrZE5GfBQcHE1oh1\nOgxVyQxuO5gVe1fw2s+v0bNJT4a0G+J0SEX67Td48kno2xcGD3Y6GuUEX9s8Mj1HylNKld5Ll71E\nrya9GL5gOFsOb3E6nEIZAyNGQEgIvPmm9ihbWfmaLDaJyN+BYBFpISJvAMu9rSQiV4rINhHZKSL5\n7hUUkVgR+UFE1onIBhG52mPZGPd620REL6WpCic0OJQ5g+ZQNawqA+YM4FTaKadDKtCMGfD99/Dy\nyxAT43Q0yinFGfyoLZAGfAScBEYXtYK7A8IpwFVAG2CoiLTJU+wJYI4xphMwBHjTvW4b9+e2WNdL\n3nRvT6kKpVG1Rnw88GO2H9nOsAXD8OWGE386cAAefhguuADuvNPpaJSTfEoWxpjTxpixxpiuxpgE\n9/tUL6t1A3YaY3a5OyCcDVyXd9NYz2wA1MC6VRd3udnGmDRjzG5gp3t7SlU4FzW7iBf6vMDcLXN5\n/efydbH7vvush/CmT4cgvVGvUvP2UN6CopZ7uRuqMbDX43My0D1PmXHAYhEZBVQFLvVYd2WedQPr\nhnSliuHRvz3KiuQVPPrNoyQ0SuD82POdDon58+GTT6znKlq2dDoa5TRvd0P1xKrwPwJ+Bopzaaug\nsnnPsYcCM40xr4pIT2CWiLTzcV1EZAQwAiA2Vu9oUoFLRJh53UwSpicweO5g1t21jvpR9R2L59gx\n66yiUyerGUopbyeWDYDHgXbA68BlwJ/GmKXGmKVe1k0Gmnh8jiGnmSnbMGAOgDFmBRABRPu4LsaY\nae5msYS6det6CUep8q1GRA3mD57P8dTjDJk/xOd+t+zwyCNw+DC88451F5RSRSYLY0yWMeYrY8xt\nQA+sawdL3M1G3qwGWohInIiEYV2wztus9TvQB0BEWmMli8PuckNEJFxE4oAWwKpifC+lAlKH+h2Y\neu1UliQtYex3Yx2J4dtvrTugHnnEOrNQCnx4KE9EwoFrsJqMmgGTgE+8rWeMyRSR+4CvgWBghjFm\ns4iMBxKNMQuAh4HpIvIgVjPT7ca6HWSziMwBtmB1WHivMT4OTKBUgLul4y0s37ucl5a/RI+YHvRv\n3d9v+/7rL+uZihYt4Omn/bZbFQCK7BtKRN7DaoL6EuvupE3+Cqy4KnsX5apiSctMo/e7vdl2ZBuJ\ndybSok4Lv+z34Ydh4kRYutS6XVZVfL72DeXtmsUtQEvgAWC5iJx0T6dE5GRZBKqUyi88JJx5g+cR\nGhTKgDkDOJ1x2vZ9rloFr71mDZWqiULl5e2aRZAxppp7qu4xVTPGVC9qXaVU6cTWiOW/N/yXTYc2\nMXLhSFsf2EtPh2HDoGFDePFF23ajApg+ZqNUOXbFuVcw7qJxzNowi6lrptq2nxdfhE2b4D//gRo1\nbNuNCmCaLJQq55644AmuOvcqHvjqAVbtK/ubArdsgeeegxtvtHqVVaogmiyUKueCJIgPbviAhlEN\nGTR3EH+e/rPMtp2VBcOHW8OjTprkvbyqvDRZKBUAakfWZv7g+RxMOchNn9xElqts7iR/801YscK6\nsF2vnvfyqvLSZKFUgOjSqAuTr5rM4t8WM37p+FJvb88eGDPGGkv75pvLIEBVoWmyUCqADO88nNvj\nb2f8j+NZtGNRibdjDIwcab2fOlUHNFLeabJQKoCICFOunkLH+h25+ZObSTqeVKLtfPABfPUVvPAC\nNG1atjGqikmThVIBpkpoFeYPno/LuBg4ZyCpmd6Glsnt0CEYPRp69oR77rEpSFXhaLJQKgCdU/sc\n3u//PmsOrOH+L+8v1roPPAApKfD22xCs408qH2myUCpA9TuvH2POH8P0tdN5d927Pq3z+ecwezaM\nHQtt8g5yrFQRiuxIMJBoR4KqMsp0ZXLFB1ewfO9yVgxbQXyD+ELLnjgBbdtCrVqwZg2EhfkxUFVu\nlVVHgkqpciwkKISPBnxEncg6DJgzgOOpxwst+9hjcOCANaCRJgpVXJoslApw9arWY+6gufx+4ndu\n/fRWXMaVr8yPP8Jbb1nXK7p1cyBIFfA0WShVAfRs0pOJl0/k8+2f8+L/cncbe+aM1aVHXBw8+6xD\nAaqAp6PrKlVB3NftPpYnL+eJH56gW+Nu9GneB4Dx42HHDvjmG6ha1eEgVcDSMwulKggRYXrf6bSK\nbsXQ+UNJPpnMunXw8stwxx1w6aVOR6gCmSYLpSqQqLAo5g+ez5nMMwyaPZR/DHMRHQ2vvup0ZCrQ\naTOUUhVMq+hWzOg3g8GjE2FdEPPmWbfLKlUamiyUqoDiwwYR/OP1ZLX6hPSWacBQp0NSAU6boZSq\nYFwuuPNOiIoMIWH4ewz/fDibD212OiwV4Cr0mUVGRgbJycmkphavo7WKJiIigpiYGEJDQ50ORfnB\n9OmwdCm8/bZw1eD/0HlqZwbMGcDqO1dTLbya0+GpAFWhu/vYvXs31apVo06dOkgl7bDfGMORI0c4\ndeoUcXFxToejbLZvn9XnU0ICfPutNU7F0qSl9Hm/Dze0voGPB35caf8WVMG0uw8gNTW1UicKsG6n\nrFOnTqU/u6oMjIG774aMDJg2LWdAowubXcgLfV5g7pa5vLbyNWeDVAGrQicLoFInimx6DCqHOXOs\nXmXHj4dzzsm97JG/PcL1ra7n0W8e5ac9PzkToApoFT5ZOC04OJj4+PizU1JSktMhqQroyBEYNcpq\nfho9Ov9yEWHmdTNpXqs5N867kYMpB/0fpApotiYLEblSRLaJyE4ReayA5f8WkfXuabuIHPdYluWx\nbIGdcdopMjKS9evXn52aNWvmdEiqAnroITh2zOpRNqSQ21ZqRNRg/uD5HE89zpB5Q8h0Zfo3SBXQ\nbEsWIhIMTAGuAtoAQ0Uk13ArxpgHjTHxxph44A3gE4/FZ7KXGWP62RVneTBp0iTatGlDhw4dGDJk\nCAApKSnccccdtG/fng4dOjB//nyHo1Tl1ddfw/vvwz//CR06FF22ff32TOs7jaV7lvL4d4/7J0BV\nIdh562w3YKcxZheAiMwGrgO2FFJ+KPC0bdGMHg3r15ftNuPj4bWiLxieOXOG+HhrQJq4uDg+/fTT\nfGUmTJjA7t27CQ8P5/hx6+Tq2WefpUaNGmzcuBGAY8eOlW3sqkJISYERI6BVK3jiCd/WubnDzSzf\nu5yXl79Mj5ge3ND6BnuDVBUAaZa/AAAWp0lEQVSCncmiMbDX43My0L2ggiLSFIgDvveYHSEiiUAm\nMMEY85ldgdopuxmqKB06dOCmm27i+uuv5/rrrwfg22+/Zfbs2WfL1NL+GlQBxo6FvXvhp58gIsL3\n9f59xb9J3J/I7Z/dTrt67WhZp6V9QaoKwc5kUdAtOIU91DEEmGeMyfKYF2uM2S8izYHvRWSjMea3\nXDsQGQGMAIiNjS06Gi9nAP50xx13sG7dOho1asSiRYv44osv+PHHH1mwYAHPPvssmzdvxhijdzGp\nIq1YAW+8AffcA716FW/d8JBw5g2ed/aBvZXDVlI1TPsvV4Wz8wJ3MtDE43MMsL+QskOAjzxnGGP2\nu193AUuATnlXMsZMM8YkGGMS6tatWxYx+8W7777L+vXrWbRoES6Xi71793LxxRfz0ksvcfz4cVJS\nUrj88suZPHny2XW0GUp5SkuDYcMgJgZeeKFk24itEcuHAz5k86HNjPxiJBXlAV1lDzuTxWqghYjE\niUgYVkLId1eTiJwH1AJWeMyrJSLh7vfRQC8Kv9YR0LKysrj55ptp3749nTp14sEHH6RmzZo88cQT\nHDt2jHbt2tGxY0d++OEHp0NV5ci//gVbt8LUqVCtFD14XH7O5Txz0TN8sOED3kp8q+wCVBWObc1Q\nxphMEbkP+BoIBmYYYzaLyHgg0RiTnTiGArNN7p81rYGpIuLCSmgTjDEBmSxSUlKKXB4aGsr//ve/\nfPOjoqJ477337ApLBbBNm6yziZtugquuKv32xl4wlhXJK3jgqwfo0qgL3RrrIN0qvwrdN9TWrVtp\n3bq1QxGVL3osKoasLPjb32DXLuvMIjq6bLZ79MxROk/tjMu4WHvXWqKrlNGGVbmnfUMpVQFNmgSr\nVlmvZZUoAGpH1mb+4Pkc+usQN31yE1muLO8rqUpFk4VSAWL3butZimuuAfezm2WqS6MuTL56Mot/\nW8wzS58p+x2ogKbJQqkAYIz18F1wMPznPzk9ypa1YZ2GcUf8HTz747N8sf0Le3aiApImC6UCwMyZ\n1vgUL74ITZp4LV5iIsKUq6fQsX5Hbvn0FnYf223fzlRA0WShVDl38KDVUWDv3nDXXfbvLzI0kvmD\n5+MyLgbOHUhqpo6FojRZ2C67i/J27doxaNAgTp8+7XRIKsCMGgVnzljDpQb56S/2nNrnMKv/LNYe\nWMuoRaP8s1NVrmmysFl231CbNm0iLCyMt97K/eCTMQaXy+VQdKq8+/RTmDcPnnoKzjvPv/vue15f\nHj//cd5e9zYz1s3w785VuaPJwo969+7Nzp07SUpKonXr1txzzz107tyZvXv3snjxYnr27Ennzp0Z\nNGjQ2Yf5Vq9ezd/+9jc6duxIt27dOHXqlMPfQvnL8eNw773QsSM8+qgzMYy/eDx94vpw76J7WXdg\nnTNBqHLBzo4Ey5XRX41m/cGy7aI8vkE8r13pWweFmZmZfPnll1x55ZUAbNu2jXfffZc333yTP//8\nk+eee45vv/2WqlWr8uKLLzJx4kQee+wxbrzxRj7++GO6du3KyZMniYyMLNPvoMqvRx+FP/6whkoN\nDXUmhuCgYD4c8CGdp3Zm4NyBJN6ZSK1I7QG5MtIzC5tlj2eRkJBAbGwsw4YNA6Bp06b06NEDgJUr\nV7JlyxZ69epFfHw87733Hnv27GHbtm00bNiQrl27AlC9enVCChsGTVUo338Pb78NDz8MXbo4G0u9\nqvWYO2gue0/s5bbPbsNltNm0Mqo0NY+vZwBlrbDxLKpWzekO2hjDZZddxkcf5ep4lw0bNmg35ZXQ\n6dNw551w7rkwbpzT0Vh6NunJxCsmMurLUUz43wQe762j7FU2emZRDvTo0YNly5axc+dOAE6fPs32\n7dtp1aoV+/fvZ/Xq1QCcOnWKzEwdN7mie/ppq++n6dOhShWno8lxb9d7GdpuKE/+8CTf7vrW6XCU\nn2myKAfq1q3LzJkzGTp0KB06dKBHjx78+uuvhIWF8fHHHzNq1Cg6duzIZZddRmqq3vNekSUmwsSJ\n1pnFRRc5HU1uIsK0vtNoFd2KofOHknwy2emQlB9pr7OVhB6L8i8jAxIS4PBh2LIFatZ0OqKC/frn\nr3Sd3pV29dqx9PalhAWHOR2SKgXtdVapAPPSS7Bhg9X3U3lNFACtolvx7nXvsjJ5JQ9//bDT4Sg/\n0WShVDnw668wfjwMGgTXXed0NN4NbDOQh3o8xOTVk/lw44dOh6P8oNLcDVWYrCw4cCCnF0+R3O+9\nvfo6rzjrl2Z7KvC4XDB8OFStCm+84XQ0vptw6QRW7V/FnZ/fScf6HWlbr63TISkbVfpk4XJZDz5V\nkEs3hSabQ4fgkkusLq6DgqzX7Km4n4ODITYW2rbNmerVc+47B7r//AeWLbN6lq1f3+lofBcaHMrH\nAz+m89TO3DDnBlbfuZrq4dWdDkvZpNIni9DQnIeeshNGUa++lClOWTvX93xNSYG+fa0zKZfLes2e\nfPmckQGpqdbnjAxYvtzqjiJbdLSVNNq1y51E6tTJf8xVjt9/h8ceg8svh1tvdTqa4mtUrREfD/yY\nPu/3YdiCYcwZOEefDaqgKn2y8FSRm3P++gumTSu77RljNd9t3pwzbdoE778Pnt1X1a+fO3lkT7W0\nxwiMgZEjrWQ8dWrg/r+7sNmFTLh0Ao9+8yj/XvlvHur5kNMhKRtosrBZcHAw7du3JzMzk7i4OGbN\nmkXNMrzVZebMmSQmJjJ58mTGjRtHVFQUjzzySJltvzAi0KiRNV12Wc58YyA5OXcS2bwZ3n3XOrvJ\n1qhRwUmkeiVqxfjwQ/jyS/j3v6FZM6ejKZ2Hez7MiuQV/N83/0fXRl3p3bS30yGpMqbJwmae3X3c\ndtttTJkyhbFjxzoclX1ErJHcmjQBd5+JgPXree9e6+zDM4lMnWqN1ZAtJiZ/c1abNhAV5f/vYqfD\nh+GBB6B7d2u8ikAnIszoN4Ouf3Rl8LzBrLtrHQ2iGjgdlipDmiz8qGfPnmzYsOHs55dffpk5c+aQ\nlpZG//79eeaZZwB4//33eeWVVxAROnTowKxZs/j888957rnnSE9Pp06dOvz3v/+lfgBdDQ0KgqZN\nremaa3Lmu1yQlJTTjJWdRJYsgbS0nHJNm+Y+A2nXDlq3Ll/dYRTH6NFw8iS88451w0BFUCOiBvMH\nz6f72925cd6NfHfrd4QEaRVTUVSaf8nRo6GA/vxKJT4eXvOxf8KsrCy+++67s73OLl68mB07drBq\n1SqMMfTr148ff/yROnXq8Pzzz7Ns2TKio6M5evQoAOeffz4rV65ERHj77bd56aWXePXVV8v2Czkg\nKAiaN7emvn1z5mdlWf0j5W3O+vZbSE+3yohAXFz+pqxWraA89+T+xRdWE9TTT1vxViTt67dnWt9p\n3PLpLYz5dgwvX/6y0yGpMlJpkoVTsrsoT0pKokuXLlzmbuBfvHgxixcvplOnTgCkpKSwY8cOfvnl\nFwYOHEh0dDQAtWvXBiA5OZkbb7yRAwcOkJ6eTlxcnDNfyE+Cg6FFC2u6/vqc+ZmZsHNn/iTy5ZfW\nMshJQHnvzDrvPAgPd+b7ZDt50rqo3bYtjBnjbCx2ubnDzazYu4JXVrxCzyY9uaH1DU6HpMpApUkW\nvp4BlLXsaxYnTpzg2muvZcqUKdx///0YYxgzZgx33XVXrvKTJk0q8NbDUaNG8dBDD9GvXz+WLFnC\nuPLSd7WfhYRYZw6tWsGAATnz09Nhx478SeTzz62zFLAS0Lnn5m7KatvWSkhhfureaMwY2LcP5s51\nPnHZaeIVE0k8kMjtn91Ou3rtaFmnpdMhqVKqNMnCaTVq1GDSpElcd9113H333VxxxRU8+eST3HTT\nTURFRbFv3z5CQ0Pp06cP/fv358EHH6ROnTocPXqU2rVrc+LECRo3bgzAe++95/C3KX/CwnKSgKe0\nNNi+PfftvRs3wmefWddLwEpALVvmb85q0cJaVlZ++gnefNO6sO0e96rCCg8JZ+6guXSe2pkBcwaw\ncthKqoZV9b6iKrdsTRYiciXwOhAMvG2MmZBn+b+Bi90fqwD1jDE13ctuA55wL3vOGBPwNWSnTp3o\n2LEjs2fP5pZbbmHr1q307NkTgKioKD744APatm3L2LFjufDCCwkODqZTp07MnDmTcePGMWjQIBo3\nbkyPHj3YvXu3w98mMISHQ/v21uQpNdXqj8nzLGTNGpg3L+dBxrAwq+kqbxI555ziX5ROTbW69Gja\nFJ57rmy+W3kXWyOWDwd8yJUfXMldC+9iVv9Z+sBeALOti3IRCQa2A5cBycBqYKgxZksh5UcBnYwx\n/xCR2kAikAAYYA3QxRhzrLD9aRflRdNj4ZvTp2Hr1vzNWUlJOWXCw61msLzXROLirOslBRk7Fv71\nL/j6a+tp7crk2aXP8tSSp5hy9RTu6XqP0+GoPHztotzOM4tuwE5jzC53QLOB64ACkwUwFHja/f4K\n4BtjzFH3ut8AVwIfFbKuUmWiShWr+5e8416npFhjTHgmkB9/hP/+N6dMZKR1O2/eW3yPH7e6H7/t\ntsqXKADGXjCWlftWMvqr0XRp2IXuMd2dDkmVgJ3JojGw1+NzMlDg/xIRaQrEAd8XsW5jG2JUyidR\nUdCtmzV5OnkyJ4lkPyfy3Xcwa1bucvXqWSPgVUZBEsSs/rPoMq0LA+cOZO2ItdStWtfpsFQx2Zks\nCmqcLKzNawgwzxiTVZx1RWQEMAIgNja2JDEqVSrVq1sXq/NesD52LCeJbN1q3f7rvgu6UqodWZt5\ng+bRa0YvbvrkJr686UuCgyrI04iVhJ2DHyUDTTw+xwD7Cyk7hNxNTD6ta4yZZoxJMMYk1K2rv1RU\n+VGrFvTqBSNGWH0/XXih0xE5r0ujLky+ejLf7PqGcUvGOR2OKiY7k8VqoIWIxIlIGFZCWJC3kIic\nB9QCVnjM/hq4XERqiUgt4HL3PKVUABveeTj/iP8Hz/30HF9s/8LpcFQx2JYsjDGZwH1YlfxWYI4x\nZrOIjBeRfh5FhwKzjcdtWe4L289iJZzVwPjsi91KqcA2+erJxDeI5+ZPb2b3Mb0FPFDYOga3MWaR\nMaalMeYcY8zz7nlPGWMWeJQZZ4x5rIB1ZxhjznVP79oZp90OHjzIkCFDOOecc2jTpg1XX30127dv\nZ/v27Vx99dWce+65tG7dmsGDB/PHH3+wZMkSatSoQadOnWjVqpVfuhxXyl8iQyOZP3g+AAPmDCA1\nM9XhiJQvbE0WCowx9O/fn4suuojffvuNLVu28K9//Ys//viDa665hrvvvpudO3eydetW7r77bg4f\nPgxA7969WbduHevWrWPhwoUsW7bM4W+iVNlpXqs571//PusOruO+Rfc5HY7ygSYLm/3www+EhoYy\ncuTIs/Pi4+PZsWMHPXv2pK9HV6sXX3wx7dq1y7V+ZGQk8fHx7Nu3z28xK+UPfc/ry+PnP847697h\nnbXvOB2O8qLS9A21Y/QOUtaneC9YDFHxUbR4rUWRZTZt2kSXvE94FTE/r2PHjrFjxw4uuOCCEsep\nVHk1/uLx/LzvZ+5ddC+dG3amU8NOToekCqFnFuXUTz/9RIcOHWjQoAHXXnstDRroqGOq4gkOCuaj\nAR9Rt2pdBswZwLEzhfbooxxWac4svJ0B2KVt27bMmzevwPlLly4tdL3evXuzcOFCtm/fzvnnn0//\n/v2Jj4+3M1SlHFG3al3mDprLBe9ewK2f3cr/G/L/CBL9HVve6L+IzS655BLS0tKYPn362XmrV6/m\n3HPPZfny5XzxRc695l999RUbN27MtX7Lli0ZM2YML774ot9iVsrfesT0YOIVE1m4fSEv/PSC0+Go\nAlSaMwuniAiffvopo0ePZsKECURERNCsWTNee+01Fi5cyOjRoxk9ejShoaF06NCB119/nSNHjuTa\nxsiRI3nllVfYvXt3hR8hT1Ve93a9l+V7l/PkD0/iMi5qR9YmSIIq3BSo3bTb1kW5v2kX5UXTY6EC\nwV/pf3HBzAtYe2Ct06HYqqwTUMf6HZk9cHaJYikPXZQrpVSxVA2ryqrhqzieehyXcemUd6Lg+c1r\nNbf930aThVKqXAkOCqZOlTpOh6Hy0AvcSimlvKrwyaKiXJMpDT0GSqnSqtDJIiIigiNHjlTqytIY\nw5EjR4iIiHA6FKVUAKvQ1yxiYmJITk4+2zlfZRUREUFMTIzTYSilAliFThahoaH6XIJSSpWBCt0M\npZRSqmxoslBKKeWVJgullFJeVZjuPkTkMLCnFJuIBv4so3DKksZVPBpX8WhcxVMR42pqjKnrrVCF\nSRalJSKJvvSP4m8aV/FoXMWjcRVPZY5Lm6GUUkp5pclCKaWUV5osckxzOoBCaFzFo3EVj8ZVPJU2\nLr1moZRSyis9s1BKKeVVpUoWIjJDRA6JyKZClouITBKRnSKyQUQ6l5O4LhKREyKy3j095ae4mojI\nDyKyVUQ2i8gDBZTx+zHzMS6/HzMRiRCRVSLyizuuZwooEy4iH7uP188i0qycxHW7iBz2OF7D7Y7L\nY9/BIrJORBYWsMzvx8uHmJw8VkkistG938QCltv392iMqTQTcAHQGdhUyPKrgS8BAXoAP5eTuC4C\nFjpwvBoCnd3vqwHbgTZOHzMf4/L7MXMfgyj3+1DgZ6BHnjL3AG+53w8BPi4ncd0OTPb3/zH3vh8C\nPizo38uJ4+VDTE4eqyQguojltv09VqozC2PMj8DRIopcB7xvLCuBmiLSsBzE5QhjzAFjzFr3+1PA\nVqBxnmJ+P2Y+xuV37mOQ4v4Y6p7yXhS8DnjP/X4e0EdEpBzE5QgRiQGuAd4upIjfj5cPMZVntv09\nVqpk4YPGwF6Pz8mUg0rIrae7GeFLEWnr7527T/87Yf0q9eToMSsiLnDgmLmbL9YDh4BvjDGFHi9j\nTCZwArB9DFEf4gIY4G66mCciTeyOye014P8AVyHLnThe3mICZ44VWEl+sYisEZERBSy37e9Rk0Vu\nBf1iKQ+/wNZiPZLfEXgD+MyfOxeRKGA+MNoYczLv4gJW8csx8xKXI8fMGJNljIkHYoBuItIuTxFH\njpcPcX0ONDPGdAC+JefXvG1E5FrgkDFmTVHFCphn2/HyMSa/HysPvYwxnYGrgHtF5II8y207Xpos\ncksGPH8lxAD7HYrlLGPMyexmBGPMIiBURKL9sW8RCcWqkP9rjPmkgCKOHDNvcTl5zNz7PA4sAa7M\ns+js8RKREKAGfmyCLCwuY8wRY0ya++N0oIsfwukF9BORJGA2cImIfJCnjL+Pl9eYHDpW2fve7349\nBHwKdMtTxLa/R00WuS0AbnXfUdADOGGMOeB0UCLSILudVkS6Yf27HfHDfgV4B9hqjJlYSDG/HzNf\n4nLimIlIXRGp6X4fCVwK/Jqn2ALgNvf7gcD3xn1l0sm48rRr98O6DmQrY8wYY0yMMaYZ1sXr740x\nN+cp5tfj5UtMThwr936riki17PfA5UDeOyht+3us0CPl5SUiH2HdJRMtIsnA01gX+zDGvAUswrqb\nYCdwGrijnMQ1ELhbRDKBM8AQuysYt17ALcBGd3s3wONArEdsThwzX+Jy4pg1BN4TkWCs5DTHGLNQ\nRMYDicaYBVhJbpaI7MT6hTzE5ph8jet+EekHZLrjut0PcRWoHBwvbzE5dazqA5+6fwOFAB8aY74S\nkZFg/9+jPsGtlFLKK22GUkop5ZUmC6WUUl5pslBKKeWVJgullFJeabJQSinllSYLpZRSXmmyUEop\n5ZUmC6WUUl79f34hHNjWEkvkAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1a1255a898>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.plot(np.arange(1, 6, 1), fsc, 'r', np.arange(1, 6, 1), prec, 'g', np.arange(1, 6, 1), recall, 'b', np.arange(1, 6, 1),ccr, 'm',np.arange(1, 6, 1),roc_auc, 'y')\n",
    "plt.ylabel('Metrics')\n",
    "plt.legend(('F-sc', 'Prec', 'Recall', 'CCR'), loc='lower left')\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using liblinear solver"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 6 candidates, totalling 30 fits\n",
      "[CV] clf__class_weight=None, clf__penalty=l1 .........................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  clf__class_weight=None, clf__penalty=l1, score=0.6140189776553413, total=  12.3s\n",
      "[CV] clf__class_weight=None, clf__penalty=l1 .........................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:   12.3s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  clf__class_weight=None, clf__penalty=l1, score=0.6013031337263418, total=  11.2s\n",
      "[CV] clf__class_weight=None, clf__penalty=l1 .........................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:   23.6s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  clf__class_weight=None, clf__penalty=l1, score=0.6044799018103713, total=  11.4s\n",
      "[CV] clf__class_weight=None, clf__penalty=l1 .........................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   3 out of   3 | elapsed:   35.0s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  clf__class_weight=None, clf__penalty=l1, score=0.5965238981998758, total=  11.4s\n",
      "[CV] clf__class_weight=None, clf__penalty=l1 .........................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   4 out of   4 | elapsed:   46.5s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  clf__class_weight=None, clf__penalty=l1, score=0.6326093606607526, total=  11.5s\n",
      "[CV] clf__class_weight=None, clf__penalty=l2 .........................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:   58.0s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  clf__class_weight=None, clf__penalty=l2, score=0.7107583774250441, total=   4.5s\n",
      "[CV] clf__class_weight=None, clf__penalty=l2 .........................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   6 out of   6 | elapsed:  1.0min remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  clf__class_weight=None, clf__penalty=l2, score=0.7163059163059163, total=   4.9s\n",
      "[CV] clf__class_weight=None, clf__penalty=l2 .........................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   7 out of   7 | elapsed:  1.1min remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  clf__class_weight=None, clf__penalty=l2, score=0.7339290861919862, total=   5.2s\n",
      "[CV] clf__class_weight=None, clf__penalty=l2 .........................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   8 out of   8 | elapsed:  1.2min remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  clf__class_weight=None, clf__penalty=l2, score=0.7340759782919167, total=   7.8s\n",
      "[CV] clf__class_weight=None, clf__penalty=l2 .........................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   9 out of   9 | elapsed:  1.3min remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  clf__class_weight=None, clf__penalty=l2, score=0.7014388489208634, total=   5.5s\n",
      "[CV] clf__class_weight=None, clf__penalty=None .......................\n",
      "[CV]  clf__class_weight=None, clf__penalty=None, score=0.0, total=   0.1s\n",
      "[CV] clf__class_weight=None, clf__penalty=None .......................\n",
      "[CV]  clf__class_weight=None, clf__penalty=None, score=0.0, total=   0.1s\n",
      "[CV] clf__class_weight=None, clf__penalty=None .......................\n",
      "[CV]  clf__class_weight=None, clf__penalty=None, score=0.0, total=   0.1s\n",
      "[CV] clf__class_weight=None, clf__penalty=None .......................\n",
      "[CV]  clf__class_weight=None, clf__penalty=None, score=0.0, total=   0.1s\n",
      "[CV] clf__class_weight=None, clf__penalty=None .......................\n",
      "[CV]  clf__class_weight=None, clf__penalty=None, score=0.0, total=   0.1s\n",
      "[CV] clf__class_weight=balanced, clf__penalty=l1 .....................\n",
      "[CV]  clf__class_weight=balanced, clf__penalty=l1, score=0.6907430469074305, total=11.9min\n",
      "[CV] clf__class_weight=balanced, clf__penalty=l1 .....................\n",
      "[CV]  clf__class_weight=balanced, clf__penalty=l1, score=0.6881219563836545, total=12.3min\n",
      "[CV] clf__class_weight=balanced, clf__penalty=l1 .....................\n",
      "[CV]  clf__class_weight=balanced, clf__penalty=l1, score=0.6696982224059528, total=14.0min\n",
      "[CV] clf__class_weight=balanced, clf__penalty=l1 .....................\n",
      "[CV]  clf__class_weight=balanced, clf__penalty=l1, score=0.6801176965111392, total=14.4min\n",
      "[CV] clf__class_weight=balanced, clf__penalty=l1 .....................\n",
      "[CV]  clf__class_weight=balanced, clf__penalty=l1, score=0.6771458117890382, total=11.2min\n",
      "[CV] clf__class_weight=balanced, clf__penalty=l2 .....................\n",
      "[CV]  clf__class_weight=balanced, clf__penalty=l2, score=0.7467090331366318, total=  12.8s\n",
      "[CV] clf__class_weight=balanced, clf__penalty=l2 .....................\n",
      "[CV]  clf__class_weight=balanced, clf__penalty=l2, score=0.748564867967853, total=  10.7s\n",
      "[CV] clf__class_weight=balanced, clf__penalty=l2 .....................\n",
      "[CV]  clf__class_weight=balanced, clf__penalty=l2, score=0.7558327558327559, total=  12.5s\n",
      "[CV] clf__class_weight=balanced, clf__penalty=l2 .....................\n",
      "[CV]  clf__class_weight=balanced, clf__penalty=l2, score=0.7495946258976142, total=  12.8s\n",
      "[CV] clf__class_weight=balanced, clf__penalty=l2 .....................\n",
      "[CV]  clf__class_weight=balanced, clf__penalty=l2, score=0.7566820276497694, total=  10.2s\n",
      "[CV] clf__class_weight=balanced, clf__penalty=None ...................\n",
      "[CV]  clf__class_weight=balanced, clf__penalty=None, score=0.0, total=   0.1s\n",
      "[CV] clf__class_weight=balanced, clf__penalty=None ...................\n",
      "[CV]  clf__class_weight=balanced, clf__penalty=None, score=0.0, total=   0.1s\n",
      "[CV] clf__class_weight=balanced, clf__penalty=None ...................\n",
      "[CV]  clf__class_weight=balanced, clf__penalty=None, score=0.0, total=   0.1s\n",
      "[CV] clf__class_weight=balanced, clf__penalty=None ...................\n",
      "[CV]  clf__class_weight=balanced, clf__penalty=None, score=0.0, total=   0.1s\n",
      "[CV] clf__class_weight=balanced, clf__penalty=None ...................\n",
      "[CV]  clf__class_weight=balanced, clf__penalty=None, score=0.0, total=   0.1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done  30 out of  30 | elapsed: 66.1min finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5, error_score=0.0,\n",
       "       estimator=Pipeline(memory=None,\n",
       "     steps=[('tfidf', TfidfTransformer(norm=None, smooth_idf=True, sublinear_tf=False,\n",
       "         use_idf=False)), ('clf', LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "          intercept_scaling=1, max_iter=100, multi_class='ovr',\n",
       "          n_jobs=None, penalty='l2', random_state=None, solver='liblinear',\n",
       "          tol=0.0001, verbose=0, warm_start=False))]),\n",
       "       fit_params=None, iid='warn', n_jobs=None,\n",
       "       param_grid={'clf__penalty': ('l1', 'l2', None), 'clf__class_weight': (None, 'balanced')},\n",
       "       pre_dispatch='2*n_jobs', refit=True, return_train_score='warn',\n",
       "       scoring=make_scorer(f1_score), verbose=10)"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipeline = Pipeline([\n",
    "    ('tfidf', TfidfTransformer(norm=None, smooth_idf=True, sublinear_tf=False,use_idf=False)),\n",
    "    ('clf', LogisticRegression(multi_class='ovr', solver='liblinear'))\n",
    "])\n",
    "\n",
    "parameters = {'clf__penalty':('l1','l2', None), 'clf__class_weight':(None, 'balanced')}\n",
    "grid = GridSearchCV(pipeline, parameters, scoring = make_scorer(f1_score), cv=5, error_score=0.0, verbose=10)\n",
    "\n",
    "grid.fit(train_feature_vectors_sparse, train_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(memory=None,\n",
       "     steps=[('tfidf', TfidfTransformer(norm=None, smooth_idf=True, sublinear_tf=False,\n",
       "         use_idf=False)), ('clf', LogisticRegression(C=1.0, class_weight='balanced', dual=False,\n",
       "          fit_intercept=True, intercept_scaling=1, max_iter=100,\n",
       "          multi_class='ovr', n_jobs=None, penalty='l2', random_state=None,\n",
       "          solver='liblinear', tol=0.0001, verbose=0, warm_start=False))])"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision =  0.819522704674\n",
      "Recall =  0.700127424607\n",
      "F_score =  0.862446157434\n",
      "CCR =  0.946164176599\n",
      "ROC_AUC =  0.889980270448\n",
      "\n",
      "Confusion Matrix: \n",
      " [[51418  2118]\n",
      " [ 1089  4945]]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "clf = LogisticRegression(C=1.0, class_weight='balanced', dual=False,\n",
    "          fit_intercept=True, intercept_scaling=1, max_iter=100,\n",
    "          multi_class='ovr', n_jobs=None, penalty='l2', random_state=None,\n",
    "          solver='liblinear', tol=0.0001, verbose=0, warm_start=False)\n",
    "\n",
    "clf.fit(train_feature_vectors_sparse, train_labels)\n",
    "\n",
    "predictions = clf.predict(test_feature_vectors_sparse)\n",
    "confmat = confusion_matrix(test_labels, predictions)\n",
    "\n",
    "precision = confmat[1,1]/(confmat[1,1] + confmat[1,0])\n",
    "recall = confmat[1,1]/(confmat[1,1] + confmat[0,1])\n",
    "fScore = f1_score(test_labels, predictions, average='macro')\n",
    "ccr = (confmat[0,0] + confmat[1,1])/(sum(sum(confmat)))\n",
    "roc_auc = roc_auc_score(test_labels, predictions)\n",
    "print(\"Precision = \",precision)\n",
    "print(\"Recall = \",recall)\n",
    "print(\"F_score = \",fScore)\n",
    "print(\"CCR = \",ccr)\n",
    "print(\"ROC_AUC = \", roc_auc)\n",
    "print()\n",
    "print(\"Confusion Matrix: \\n\", confmat)\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
