{"cells":[
 {
  "cell_type": "markdown",
  "metadata": {},
  "source": "This script inspired by:\n\nhttps://www.kaggle.com/gpayen/d/snap/amazon-fine-food-reviews/building-a-prediction-model/notebook https://districtdatalabs.silvrback.com/modern-methods-for-sentiment-analysis\n\nThe review score is made binary by splitting {1,2} and {4,5} and throwing out scores of 3.\n\nA simple averaging is used with word2vec embeddings and logistic \nregression used to score an AUC of 0.88 on a held out test set.\n"
 },
 {
  "cell_type": "code",
  "execution_count": null,
  "metadata": {
   "collapsed": false
  },
  "outputs": [],
  "source": "import nltk\nfrom nltk.corpus import stopwords \nstops = set(stopwords.words(\"english\"))\nfrom gensim.models import Word2Vec\nfrom bs4 import BeautifulSoup \nimport re\nimport sqlite3\nimport pandas as pd\nimport numpy as np\nimport string\nimport matplotlib.pyplot as plt\nfrom sklearn.cross_validation import train_test_split\nfrom sklearn.metrics import roc_auc_score\nfrom sklearn import linear_model\n\n#location of sqlite\ndataLoc= '../input/database.sqlite'\n\npd.set_option('max_colwidth', 100)"
 },
 {
  "cell_type": "code",
  "execution_count": null,
  "metadata": {
   "collapsed": false
  },
  "outputs": [],
  "source": "def binarize_score(score):\n    \"\"\"\n    set scores of 1-3 to 0 and 4-5 as 1\n    \"\"\"\n    \n    if score <3:\n        return 0\n    else:\n        return 1\n\n\n\ndef review_to_words( review ):\n    \"\"\"\n    Return a list of cleaned word tokens from the raw review\n    \n    \"\"\"\n        \n    #Remove any HTML tags and convert to lower case\n    review_text = BeautifulSoup(review).get_text().lower() \n    \n    #Replace smiliey and frown faces, ! and ? with coded word SM{int} in case these are valuable\n    review_text=re.sub(\"(:\\))\",r' SM1',review_text)\n    review_text=re.sub(\"(:\\()\",r' SM2',review_text)\n    review_text=re.sub(\"(!)\",r' SM3',review_text)\n    review_text=re.sub(\"(\\?)\",r' SM4',review_text)\n    \n    #keep 'not' and the next word as negation may be important\n    review_text=re.sub(r\"not\\s\\b(.*?)\\b\", r\"not_\\1\", review_text)\n    \n    #keep letters and the coded words above, replace the rest with whitespace\n    nonnumbers_only=re.sub(\"[^a-zA-Z\\_(SM\\d)]\",\" \",review_text)  \n    \n    #Split into individual words on whitespace\n    words = nonnumbers_only.split()                             \n    \n    #Remove stop words\n    words = [w for w in words if not w in stops]   \n    \n    return (words)\n\n\n\ndef avg_word_vectors(wordlist,size):\n    \"\"\"\n    returns a vector of zero for reviews containing words where none of them\n    met the min_count or were not seen in the training set\n    \n    Otherwise return an average of the embeddings vectors\n    \n    \"\"\"\n    \n    sumvec=np.zeros(shape=(1,size))\n    wordcnt=0\n    \n    for w in wordlist:\n        if w in model:\n            sumvec += model[w]\n            wordcnt +=1\n    \n    if wordcnt ==0:\n        return sumvec\n    \n    else:\n        return sumvec / wordcnt\n\n\n"
 },
 {
  "cell_type": "code",
  "execution_count": null,
  "metadata": {
   "collapsed": false
  },
  "outputs": [],
  "source": "connection = sqlite3.connect(dataLoc)\nreviews = pd.read_sql_query(\"\"\" SELECT Score, Summary, Text FROM Reviews WHERE Score != 3 \"\"\", connection)\n\n   \nreviews['Score_binary']=reviews['Score'].apply(binarize_score)\nreviews['word_list']=reviews['Summary'].apply(review_to_words)\n\n\nprint (reviews.head(n=10))\n"
 },
 {
  "cell_type": "code",
  "execution_count": null,
  "metadata": {
   "collapsed": false
  },
  "outputs": [],
  "source": "X_train, X_test, y_train, y_test = train_test_split(reviews['word_list'], reviews['Score_binary'], test_size=0.2, random_state=42)\n\n\n#size of hidden layer (length of continuous word representation)\ndimsize=400\n\n#train word2vec on 80% of training data\nmodel = Word2Vec(X_train.values, size=dimsize, window=5, min_count=5, workers=4)\n\n#create average vector for train and test from model\n#returned list of numpy arrays are then stacked \nX_train=np.concatenate([avg_word_vectors(w,dimsize) for w in X_train])\nX_test=np.concatenate([avg_word_vectors(w,dimsize) for w in X_test])"
 },
 {
  "cell_type": "code",
  "execution_count": null,
  "metadata": {
   "collapsed": false
  },
  "outputs": [],
  "source": "#basic logistic regression with SGD\nclf = linear_model.SGDClassifier(loss='log')\nclf.fit(X_train, y_train)\np=clf.predict_proba(X_test)\nroc_auc_score(y_test,p[:,1])"
 }
],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"}}, "nbformat": 4, "nbformat_minor": 0}